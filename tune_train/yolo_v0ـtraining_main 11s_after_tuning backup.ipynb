{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b26f5d6",
   "metadata": {},
   "source": [
    "# YOLO Training\n",
    "- Support for YOLOv8, YOLOv9, YOLOv10, YOLO11, YOLO12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e53f76",
   "metadata": {},
   "source": [
    "# 1. Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c698714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directories\n",
    "# Detect environment: Colab or local\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n",
    "\n",
    "IS_COLAB = False\n",
    "USE_WANDB = False  # Set to False to disable W&B logging\n",
    "\n",
    "if IS_COLAB:\n",
    "    #Mount Google Drive if not already mounted\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/Drive', force_remount=True)\n",
    "    # Running in Google Colab\n",
    "    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo')\n",
    "    \n",
    "    # Configure W&B API key\n",
    "    if USE_WANDB:\n",
    "        # In Colab, get API key from secrets\n",
    "        from google.colab import userdata\n",
    "        wandb_api_key = userdata.get('wandb_api_key')\n",
    "        os.environ['WANDB_API_KEY'] = wandb_api_key\n",
    "        print('‚úì W&B API key loaded from Colab secrets')\n",
    "\n",
    "    DATASET_BASE_DIR = Path('/computer_vision_yolo')\n",
    "\n",
    "else:\n",
    "    # Running locally\n",
    "    BASE_DIR = Path.cwd().parent\n",
    "    if USE_WANDB:\n",
    "        print('‚úì Running locally - W&B will use existing login or prompt')\n",
    "    \n",
    "    DATASET_BASE_DIR = Path.cwd().parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8064a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ! cd /content/Drive/MyDrive/ksu_yolo_2025 && git clone https://github.com/m3mahdy/computer_vision_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c67ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cd {BASE_DIR} && pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f33666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download limited dataset\n",
    "# !mkdir {DATASET_BASE_DIR}\n",
    "# !cd {BASE_DIR}/dataset && cp 8_download_extract_other_datasets.py {DATASET_BASE_DIR} && cd {DATASET_BASE_DIR} && python 8_download_extract_other_datasets.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ddb177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "109394c4",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6f98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n",
      "‚úì Device: cuda\n",
      "  GPU: NVIDIA GeForce RTX 4070 SUPER\n",
      "  CUDA Version: 11.8\n",
      "  Available Memory: 12.88 GB\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (uncomment if running in Colab)\n",
    "# !pip install -q ultralytics wandb pyyaml\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "import wandb\n",
    "\n",
    "# YOLO imports\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ReportLab imports for PDF generation\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors as rl_colors\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib for notebook display\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'‚úì Libraries imported successfully')\n",
    "print(f'‚úì Device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'  CUDA Version: {torch.version.cuda}')\n",
    "    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659c792",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163f0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è  CONFIGURATION MODE: Using Tuned Hyperparameters\n",
      "   üìÇ Using specified tuning run: yolo11s_finetuned_20251201_tune_20251201_050018\n",
      "   ‚úì Found best hyperparameters: /home/adminai/src-code/CV/project_repo/tune_train/tune/yolo11s_finetuned_20251201_tune_20251201_050018/best_hyperparameters.json\n",
      "\n",
      "üÜï NEW TRAINING MODE: Creating new run \"yolo11s_train_20251201_081829\"\n",
      "================================================================================\n",
      "CONFIGURATION SUMMARY\n",
      "================================================================================\n",
      "Environment: Local\n",
      "Base Directory: /home/adminai/src-code/CV/project_repo\n",
      "Model: yolo11s\n",
      "Dataset: bdd100k_yolo_limited\n",
      "Data YAML: /home/adminai/src-code/CV/project_repo/tmp/yolo11s/data.yaml\n",
      "  Dataset path in YAML: /home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited\n",
      "Classes: 10\n",
      "Class Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n",
      "Device: cuda\n",
      "Epochs Final Training: 70\n",
      "Batch Size: 16\n",
      "Image Size: 640\n",
      "Configuration Mode: Tuned Hyperparameters\n",
      "Tuning Run: yolo11s_finetuned_20251201_tune_20251201_050018\n",
      "Training Directory: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829\n",
      "W&B Logging: Enabled\n",
      "  Training Project: yolo-bdd100k_yolo_limited-training\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Base directories\n",
    "# Detect environment: Colab or local\n",
    "\n",
    "IS_COLAB = 'COLAB_GPU' in os.environ or os.path.exists('/content')\n",
    "\n",
    "IS_COLAB = False\n",
    "USE_WANDB = False  # Set to False to disable W&B logging\n",
    "\n",
    "if IS_COLAB:\n",
    "    #Mount Google Drive if not already mounted\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/Drive', force_remount=True)\n",
    "    # Running in Google Colab\n",
    "    BASE_DIR = Path('/content/Drive/MyDrive/ksu_yolo_2025/computer_vision_yolo')\n",
    "    \n",
    "    # Configure W&B API key\n",
    "    if USE_WANDB:\n",
    "        # In Colab, get API key from secrets\n",
    "        from google.colab import userdata\n",
    "        wandb_api_key = userdata.get('wandb_api_key')\n",
    "        os.environ['WANDB_API_KEY'] = wandb_api_key\n",
    "        print('‚úì W&B API key loaded from Colab secrets')\n",
    "\n",
    "else:\n",
    "    # Running locally\n",
    "    BASE_DIR = Path.cwd().parent\n",
    "    if USE_WANDB:\n",
    "        print('‚úì Running locally - W&B will use existing login or prompt')\n",
    "class DatasetSplit:\n",
    "    \"\"\"Constants for dataset split names\"\"\"\n",
    "    TRAIN = \"train\"\n",
    "    VAL = \"val\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Default model training configuration constants\"\"\"\n",
    "    # Image processing\n",
    "    DEFAULT_IMAGE_SIZE = 640  # Standard YOLO input size\n",
    "    \n",
    "    # Training workers\n",
    "    DEFAULT_WORKERS = 4  # Number of data loading workers\n",
    "    \n",
    "    # Early stopping and checkpointing\n",
    "    DEFAULT_PATIENCE = 15  # Epochs to wait before early stopping\n",
    "    DEFAULT_SAVE_PERIOD = 3  # Save checkpoint every N epochs\n",
    "    \n",
    "    # Augmentation timing\n",
    "    CLOSE_MOSAIC_EPOCHS = 10  # Disable mosaic augmentation in last N epochs\n",
    "    \n",
    "    # Data loading and caching\n",
    "    DEFAULT_CACHE = False  # Cache images for faster training (use True for small datasets)\n",
    "    DEFAULT_VAL = True  # Run validation during training\n",
    "    \n",
    "    # Warmup configuration\n",
    "    # MIN_WARMUP_EPOCHS = 0\n",
    "    # MAX_WARMUP_EPOCHS = 3\n",
    "    # MIN_WARMUP_MOMENTUM = 0.5\n",
    "    # MAX_WARMUP_MOMENTUM = 0.95\n",
    "    # MIN_WARMUP_BIAS_LR = 0.0\n",
    "\n",
    "    # MAX_WARMUP_BIAS_LR = 0.1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Model Selection - Choose one of the following:\n",
    "MODEL_NAME = \"yolo11s\"\n",
    "\n",
    "#yolov10n is for testing purpose only\n",
    "#Mahdy will work yolov8m\n",
    "\n",
    "\n",
    "# Selected models, to choose from, based on the performance and size:\n",
    "# YOLOv8:  'yolov8s', 'yolov8m'\n",
    "\n",
    "# YOLOv10: 'yolov10s', 'yolov10m'\n",
    "\n",
    "# YOLO12: 'yolo12s'\n",
    "\n",
    "# Directory structure\n",
    "MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n",
    "TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n",
    "\n",
    "# Dataset Selection\n",
    "# Option 1: Full dataset (~100k images) - for final optimization: \"bdd100k_yolo\"\n",
    "# Option 2: Limited dataset (representative samples) - for quick tuning: \"bdd100k_yolo_limited\"\n",
    "dataset_name = 'bdd100k_yolo_limited'\n",
    "\n",
    "\n",
    "YOLO_DATASET_ROOT = DATASET_BASE_DIR / dataset_name\n",
    "\n",
    "# data.yaml path\n",
    "DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Verify dataset exists\n",
    "if not DATA_YAML_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found: {DATA_YAML_PATH}\\n\"\n",
    "        f\"Please prepare the dataset first using process_bdd100k_to_yolo_dataset.py\"\n",
    "    )\n",
    "\n",
    "# Update data.yaml path field for Colab compatibility\n",
    "with open(DATA_YAML_PATH, 'r') as yaml_file:\n",
    "    data_config = yaml.safe_load(yaml_file)\n",
    "\n",
    "# Validate required keys in data.yaml\n",
    "required_yaml_keys = ['nc', 'names', 'path']\n",
    "missing_keys = [key for key in required_yaml_keys if key not in data_config]\n",
    "if missing_keys:\n",
    "    raise ValueError(f\"Missing required keys in data.yaml: {missing_keys}\")\n",
    "\n",
    "# Update the 'path' field to use BASE_DIR\n",
    "data_config['path'] = str(YOLO_DATASET_ROOT)\n",
    "\n",
    "# Create a temporary data.yaml with corrected paths\n",
    "temp_data_yaml = TMP_DIR / 'data.yaml'\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "with open(temp_data_yaml, 'w') as yaml_output_file:\n",
    "    yaml.dump(data_config, yaml_output_file, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "# Use the temporary data.yaml for training\n",
    "DATA_YAML_PATH = temp_data_yaml\n",
    "\n",
    "# Training Configuration\n",
    "EPOCHS_FINAL_TRAINING = 70  # Training epochs for final model = 150\n",
    "BATCH_SIZE = 16  # Batch size for training\n",
    "\n",
    "# for T4 GPU:\n",
    "# 64 for 10n, 1 epoch 30 min\n",
    "# 32 for 8m, 1 epoch 45 min\n",
    "\n",
    "# for A100 GPU:\n",
    "# 64 for 10m 1 epoch 11 min, 5 epochs completed in 0.797 hours.\n",
    "# 96 for 8m , 1 epoch 10 min, 5 epochs completed in 0.866 hours.\n",
    "\n",
    "IMAGE_SIZE = 640  # Input image size\n",
    "\n",
    "# Weights & Biases (optional)\n",
    "USE_WANDB = True  # Set to True to enable W&B logging\n",
    "WANDB_PROJECT_TRAINING = f\"yolo-{YOLO_DATASET_ROOT.name}-training\"\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION MODE: DEFAULT vs TUNED HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "# Set to True to use default YOLO configuration (no hyperparameter tuning)\n",
    "# Set to False to load hyperparameters from a tuning run\n",
    "# ============================================================================\n",
    "\n",
    "USE_DEFAULT_CONFIG = False  # Set to True to skip tuning and use default YOLO config\n",
    "\n",
    "# ============================================================================\n",
    "# TUNING RUN CONFIGURATION - SPECIFY WHICH TUNING RUN TO USE\n",
    "# ============================================================================\n",
    "# Specify the tuning run name to load best hyperparameters from\n",
    "# This should match the directory name in tune_train/tune/\n",
    "# \n",
    "# Example: TUNING_RUN_NAME = \"yolov10n_tune_20251125_143022\"\n",
    "# Leave as None to search for the latest tuning run for this model\n",
    "# Note: Only used if USE_DEFAULT_CONFIG = False\n",
    "# ============================================================================\n",
    "\n",
    "TUNING_RUN_NAME = \"yolo11s_finetuned_20251201_tune_20251201_050018\"  # Set to specific tuning run name, or None to auto-detect latest\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING RUN CONFIGURATION - RESUME OR CREATE NEW\n",
    "# ============================================================================\n",
    "# To RESUME an existing training run: Set RESUME_TRAINING_RUN_NAME to the run directory name\n",
    "# To START NEW training: Leave RESUME_TRAINING_RUN_NAME as None or empty string\n",
    "# \n",
    "# Example to resume: RESUME_TRAINING_RUN_NAME = \"yolov10n_train_20251125_150000\"\n",
    "# ============================================================================\n",
    "\n",
    "RESUME_TRAINING_RUN_NAME = None  # Set to run name to resume, or None to create new run\n",
    "\n",
    "# Find or verify tuning run (only if not using default config)\n",
    "TUNE_TRAIN_BASE = BASE_DIR / 'tune_train'\n",
    "TUNE_BASE_DIR = TUNE_TRAIN_BASE / 'tune'\n",
    "\n",
    "if USE_DEFAULT_CONFIG:\n",
    "    # Using default configuration - skip tuning run search\n",
    "    print('\\n‚öôÔ∏è  CONFIGURATION MODE: Using Default YOLO Configuration')\n",
    "    print('   No hyperparameter tuning will be applied')\n",
    "    TUNE_DIR = None\n",
    "    TUNING_RUN_NAME = None\n",
    "    best_hyperparams_path = None\n",
    "else:\n",
    "    # Using tuned hyperparameters - find or verify tuning run\n",
    "    print('\\n‚öôÔ∏è  CONFIGURATION MODE: Using Tuned Hyperparameters')\n",
    "    \n",
    "    if TUNING_RUN_NAME:\n",
    "        # Use specified tuning run\n",
    "        TUNE_DIR = TUNE_BASE_DIR / TUNING_RUN_NAME\n",
    "        if not TUNE_DIR.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Specified tuning run not found: {TUNE_DIR}\\n\"\n",
    "                f\"Available runs in {TUNE_BASE_DIR}:\\n\" +\n",
    "                '\\n'.join(f\"  - {d.name}\" for d in TUNE_BASE_DIR.glob(f'{MODEL_NAME}_tune_*') if d.is_dir())\n",
    "            )\n",
    "        print(f'   üìÇ Using specified tuning run: {TUNING_RUN_NAME}')\n",
    "    else:\n",
    "        # Auto-detect latest tuning run for this model\n",
    "        tuning_runs = sorted(TUNE_BASE_DIR.glob(f'{MODEL_NAME}_tune_*'), key=lambda p: p.name, reverse=True)\n",
    "        if not tuning_runs:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No tuning runs found for model {MODEL_NAME} in {TUNE_BASE_DIR}\\n\"\n",
    "                f\"Please run the tuning notebook first, specify TUNING_RUN_NAME, or set USE_DEFAULT_CONFIG=True\"\n",
    "            )\n",
    "        TUNE_DIR = tuning_runs[0]\n",
    "        TUNING_RUN_NAME = TUNE_DIR.name\n",
    "        print(f'   üîç Auto-detected latest tuning run: {TUNING_RUN_NAME}')\n",
    "\n",
    "    # Verify best hyperparameters exist\n",
    "    best_hyperparams_path = TUNE_DIR / 'best_hyperparameters.json'\n",
    "    if not best_hyperparams_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Best hyperparameters not found in tuning run: {best_hyperparams_path}\\n\"\n",
    "            f\"Please ensure the tuning run completed successfully\"\n",
    "        )\n",
    "\n",
    "    print(f'   ‚úì Found best hyperparameters: {best_hyperparams_path}')\n",
    "\n",
    "# Configure training run name\n",
    "if RESUME_TRAINING_RUN_NAME:\n",
    "    # Resume existing training run\n",
    "    RUN_NAME_TRAINING = RESUME_TRAINING_RUN_NAME\n",
    "    print(f'\\nüîÑ RESUME MODE: Will attempt to resume training run \"{RESUME_TRAINING_RUN_NAME}\"')\n",
    "else:\n",
    "    # Create new training run with timestamp\n",
    "    RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    RUN_NAME_TRAINING = f'{MODEL_NAME}_train_{RUN_TIMESTAMP}'\n",
    "    print(f'\\nüÜï NEW TRAINING MODE: Creating new run \"{RUN_NAME_TRAINING}\"')\n",
    "\n",
    "\n",
    "RUN_NAME_TRAINING = \"yolo11s_train_20251201_081829\"\n",
    "\n",
    "\n",
    "# Create training directory\n",
    "TRAIN_DIR = TUNE_TRAIN_BASE / 'training' / RUN_NAME_TRAINING\n",
    "TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read dataset configuration\n",
    "NUM_CLASSES = data_config['nc']\n",
    "CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n",
    "CLASS_NAME_TO_ID = {name: i for i, name in enumerate(data_config['names'])}\n",
    "\n",
    "print('=' * 80)\n",
    "print('CONFIGURATION SUMMARY')\n",
    "print('=' * 80)\n",
    "print(f'Environment: {\"Google Colab\" if \"COLAB_GPU\" in os.environ or os.path.exists(\"/content\") else \"Local\"}')\n",
    "print(f'Base Directory: {BASE_DIR}')\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n",
    "print(f'Data YAML: {DATA_YAML_PATH}')\n",
    "print(f'  Dataset path in YAML: {data_config[\"path\"]}')\n",
    "print(f'Classes: {NUM_CLASSES}')\n",
    "print(f'Class Names: {CLASS_NAMES}')\n",
    "print(f'Device: {device}')\n",
    "print(f'Epochs Final Training: {EPOCHS_FINAL_TRAINING}')\n",
    "print(f'Batch Size: {BATCH_SIZE}')\n",
    "print(f'Image Size: {IMAGE_SIZE}')\n",
    "print(f'Configuration Mode: {\"Default (No Tuning)\" if USE_DEFAULT_CONFIG else \"Tuned Hyperparameters\"}')\n",
    "if not USE_DEFAULT_CONFIG:\n",
    "    print(f'Tuning Run: {TUNING_RUN_NAME}')\n",
    "print(f'Training Directory: {TRAIN_DIR}')\n",
    "if USE_WANDB:\n",
    "    print(f'W&B Logging: Enabled')\n",
    "    print(f'  Training Project: {WANDB_PROJECT_TRAINING}')\n",
    "else:\n",
    "    print(f'W&B Logging: Disabled')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af35c3f",
   "metadata": {},
   "source": [
    "## 4. Load Base YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3deeda88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded from /home/adminai/src-code/CV/project_repo/models/yolo11s/yolo11s.pt\n",
      "YOLO11s summary: 181 layers, 9,458,752 parameters, 0 gradients, 21.7 GFLOPs\n",
      "\n",
      "üìä Model Information:\n",
      "  Model: yolo11s\n",
      "  Classes in model: 80\n",
      "  Task: detect\n",
      "  Parameters: 9.5M\n",
      "  Model Size: 0.0 MB\n",
      "  FLOPs (640x640): 21.72 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "# Load YOLO model with automatic download\n",
    "model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f'Model not found at {model_path}')\n",
    "    print(f'Downloading {MODEL_NAME} ...')\n",
    "    \n",
    "    try:\n",
    "        # Download model - ensure .pt extension for ultralytics\n",
    "        # Ultralytics expects model names with .pt extension for download\n",
    "        if not MODEL_NAME.endswith('.pt'):\n",
    "            model_name_for_download = MODEL_NAME + '.pt'\n",
    "        else:\n",
    "            model_name_for_download = MODEL_NAME\n",
    "            \n",
    "        print(f'  Requesting model: {model_name_for_download}')\n",
    "        model = YOLO(model_name_for_download)\n",
    "        \n",
    "        # Create models directory\n",
    "        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save model to our directory using export/save\n",
    "        try:\n",
    "            # Try to save using the model's save method\n",
    "            if hasattr(model, 'save'):\n",
    "                model.save(str(model_path))\n",
    "                print(f'‚úì Model downloaded and saved to {model_path}')\n",
    "                print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "            else:\n",
    "                # Fallback: copy from cache\n",
    "                cache_patterns = [\n",
    "                    str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "                    str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "                ]\n",
    "                \n",
    "                model_found = False\n",
    "                for pattern in cache_patterns:\n",
    "                    cache_paths = glob.glob(pattern, recursive=True)\n",
    "                    if cache_paths:\n",
    "                        shutil.copy(cache_paths[0], model_path)\n",
    "                        print(f'‚úì Model downloaded and saved to {model_path}')\n",
    "                        print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "                        model_found = True\n",
    "                        break\n",
    "                \n",
    "                if not model_found:\n",
    "                    print(f'‚úì Model loaded from ultralytics cache')\n",
    "                    print(f'  Note: Model is in cache, not copied to {model_path}')\n",
    "                    print(f'  This is normal and the model will work correctly')\n",
    "        except Exception as save_error:\n",
    "            print(f'‚ö†Ô∏è  Could not save model to custom location: {save_error}')\n",
    "            print(f'‚úì Model loaded successfully from ultralytics cache')\n",
    "            \n",
    "    except Exception as download_error:\n",
    "        print(f'\\n‚ùå Error downloading model: {download_error}')\n",
    "        raise\n",
    "else:\n",
    "    model = YOLO(str(model_path))\n",
    "    print(f'‚úì Model loaded from {model_path}')\n",
    "\n",
    "# Get model information\n",
    "model_info_dict = {}\n",
    "model_info_result = model.info()\n",
    "model_info_keys = [\"layers\", \"params\", \"size(MB)\", \"FLOPs(G)\"]\n",
    "\n",
    "for info_key, info_value in zip(model_info_keys, model_info_result):\n",
    "    model_info_dict[info_key] = info_value\n",
    "    \n",
    "model_params = model_info_dict.get(\"params\", 0)\n",
    "model_size_mb = model_info_dict.get(\"size(MB)\", 0)\n",
    "flops_gflops = model_info_dict.get(\"FLOPs(G)\", 0)\n",
    "\n",
    "\n",
    "print(f'\\nüìä Model Information:')\n",
    "print(f'  Model: {MODEL_NAME}')\n",
    "print(f'  Classes in model: {len(model.names)}')\n",
    "print(f'  Task: {model.task}')\n",
    "print(f'  Parameters: {model_params / 1e6:.1f}M')\n",
    "print(f'  Model Size: {model_size_mb:.1f} MB')\n",
    "print(f'  FLOPs (640x640): {flops_gflops:.2f} GFLOPs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0b94d",
   "metadata": {},
   "source": [
    "## 6. Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b15401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying YOLO dataset structure...\n",
      "\n",
      "üìÅ Dataset Root: /home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited\n",
      "  ‚úì train:  29974 images,  29974 labels\n",
      "  ‚úì val  :  10000 images,  10000 labels\n",
      "  ‚úì test :  20000 images,  20000 labels\n",
      "\n",
      "üìÑ Configuration: /home/adminai/src-code/CV/project_repo/tmp/yolo11s/data.yaml\n",
      "  Classes: 10\n",
      "  Names: {0: 'person', 1: 'rider', 2: 'car', 3: 'truck', 4: 'bus', 5: 'train', 6: 'motor', 7: 'bike', 8: 'traffic light', 9: 'traffic sign'}\n",
      "\n",
      "‚úì Dataset verified: 59,974 total images\n",
      "‚úì Ready for training\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VERIFY DATASET STRUCTURE\n",
    "# ============================================================================\n",
    "\n",
    "print('Verifying YOLO dataset structure...')\n",
    "print(f'\\nüìÅ Dataset Root: {YOLO_DATASET_ROOT}')\n",
    "\n",
    "# Check all splits using constants\n",
    "dataset_stats = {}\n",
    "for split in [DatasetSplit.TRAIN, DatasetSplit.VAL, DatasetSplit.TEST]:\n",
    "    images_dir = YOLO_DATASET_ROOT / 'images' / split\n",
    "    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n",
    "    \n",
    "    if images_dir.exists() and labels_dir.exists():\n",
    "        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n",
    "        num_labels = len(list(labels_dir.glob('*.txt')))\n",
    "        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n",
    "        print(f'  ‚úì {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n",
    "    else:\n",
    "        print(f'  ‚ö†Ô∏è  {split:5s}: Directory not found')\n",
    "        dataset_stats[split] = {'images': 0, 'labels': 0}\n",
    "\n",
    "print(f'\\nüìÑ Configuration: {DATA_YAML_PATH}')\n",
    "print(f'  Classes: {NUM_CLASSES}')\n",
    "print(f'  Names: {CLASS_NAMES}')\n",
    "\n",
    "total_images = sum(stats['images'] for stats in dataset_stats.values())\n",
    "print(f'\\n‚úì Dataset verified: {total_images:,} total images')\n",
    "print('‚úì Ready for training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03686b4",
   "metadata": {},
   "source": [
    "## 5. Load Best Hyperparameters from Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f67e089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADING BEST HYPERPARAMETERS FROM TUNING\n",
      "================================================================================\n",
      "Tuning Run: yolo11s_finetuned_20251201_tune_20251201_050018\n",
      "Hyperparameters Path: /home/adminai/src-code/CV/project_repo/tune_train/tune/yolo11s_finetuned_20251201_tune_20251201_050018/best_hyperparameters.json\n",
      "\n",
      "‚úì Loaded hyperparameters from nested structure\n",
      "\n",
      "‚úì Best Hyperparameters Loaded:\n",
      "  imgsz               : 768\n",
      "  lr0                 : 0.001427\n",
      "  mixup               : 0.068396\n",
      "  momentum            : 0.969458\n",
      "  mosaic              : 0.879214\n",
      "  optimizer           : SGD\n",
      "  warmup_bias_lr      : 0.060526\n",
      "  warmup_epochs       : 3\n",
      "  warmup_momentum     : 0.895637\n",
      "  weight_decay        : 0.000541\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD HYPERPARAMETERS (TUNED OR DEFAULT)\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "if USE_DEFAULT_CONFIG:\n",
    "    print('USING DEFAULT YOLO CONFIGURATION')\n",
    "    print('=' * 80)\n",
    "    print('No hyperparameter tuning applied - using YOLO defaults')\n",
    "    \n",
    "    # Use empty dict for hyperparameters - YOLO will use its defaults\n",
    "    best_params = {}\n",
    "    \n",
    "    print('\\n‚úì Training will use default YOLO hyperparameters')\n",
    "    print('   Default values will be applied by the YOLO model')\n",
    "    \n",
    "else:\n",
    "    print('LOADING BEST HYPERPARAMETERS FROM TUNING')\n",
    "    print('=' * 80)\n",
    "    print(f'Tuning Run: {TUNING_RUN_NAME}')\n",
    "    print(f'Hyperparameters Path: {best_hyperparams_path}')\n",
    "\n",
    "    # Load best hyperparameters from JSON\n",
    "    with open(best_hyperparams_path, 'r', encoding='utf-8') as f:\n",
    "        best_params_file = json.load(f)\n",
    "\n",
    "    # Extract only the actual hyperparameters (not metadata)\n",
    "    # The file structure has metadata fields and a 'hyperparameters' field with the actual params\n",
    "    if 'hyperparameters' in best_params_file:\n",
    "        # New format: metadata + hyperparameters nested\n",
    "        best_params = best_params_file['hyperparameters']\n",
    "        print('\\n‚úì Loaded hyperparameters from nested structure')\n",
    "    else:\n",
    "        # Old format: hyperparameters directly in root\n",
    "        # Filter out metadata fields that aren't YOLO parameters\n",
    "        metadata_keys = {'model', 'dataset_root', 'data_yaml_path', 'notes', \n",
    "                        'optimization_results', 'timestamp'}\n",
    "        best_params = {k: v for k, v in best_params_file.items() if k not in metadata_keys}\n",
    "        print('\\n‚úì Loaded hyperparameters from flat structure (filtered metadata)')\n",
    "\n",
    "    print('\\n‚úì Best Hyperparameters Loaded:')\n",
    "    for key, value in sorted(best_params.items()):\n",
    "        if isinstance(value, (int, float)):\n",
    "            if isinstance(value, float):\n",
    "                print(f'  {key:20s}: {value:.6f}')\n",
    "            else:\n",
    "                print(f'  {key:20s}: {value}')\n",
    "        else:\n",
    "            print(f'  {key:20s}: {value}')\n",
    "\n",
    "    # Load tuning metadata if available\n",
    "    tuning_metadata_path = TUNE_DIR / 'optimization_metadata.json'\n",
    "    if (not USE_DEFAULT_CONFIG and tuning_metadata_path.exists()):\n",
    "        with open(tuning_metadata_path, 'r', encoding='utf-8') as f:\n",
    "            tuning_metadata = json.load(f)\n",
    "        \n",
    "        print('\\nüìä Tuning Run Summary:')\n",
    "        print(f\"  Best Trial: {tuning_metadata.get('best_trial', 'N/A')}\")\n",
    "        print(f\"  Best mAP@0.5: {tuning_metadata.get('best_map50', 0):.4f}\")\n",
    "        print(f\"  Total Trials: {tuning_metadata.get('total_trials', 'N/A')}\")\n",
    "        print(f\"  Completed Trials: {tuning_metadata.get('completed_trials', 'N/A')}\")\n",
    "        \n",
    "        if 'optimization_duration' in tuning_metadata:\n",
    "            print(f\"  Duration: {tuning_metadata['optimization_duration']}\")\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83385af0",
   "metadata": {},
   "source": [
    "## 7. Train The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57867b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING FINAL MODEL WITH OPTIMIZED HYPERPARAMETERS\n",
      "================================================================================\n",
      "\n",
      "üì¶ Loading base model: yolo11s\n",
      "\n",
      "üöÄ Starting training...\n",
      "  Configuration: Tuned Hyperparameters\n",
      "  Epochs: 70\n",
      "  Batch Size: 16\n",
      "  Dataset: /home/adminai/src-code/CV/project_repo/tmp/yolo11s/data.yaml\n",
      "  Device: cuda\n",
      "  Resume: False\n",
      "\n",
      "üìä Applied Hyperparameters:\n",
      "  imgsz               : 768\n",
      "  lr0                 : 0.001427\n",
      "  mixup               : 0.068396\n",
      "  momentum            : 0.969458\n",
      "  mosaic              : 0.879214\n",
      "  optimizer           : SGD\n",
      "  warmup_bias_lr      : 0.060526\n",
      "  warmup_epochs       : 3\n",
      "  warmup_momentum     : 0.895637\n",
      "  weight_decay        : 0.000541\n",
      "\n",
      "This may take a while. Training progress will be displayed below.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAIN FINAL MODEL WITH OPTIMIZED HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "if USE_DEFAULT_CONFIG:\n",
    "    print('TRAINING FINAL MODEL WITH DEFAULT CONFIGURATION')\n",
    "else:\n",
    "    print('TRAINING FINAL MODEL WITH OPTIMIZED HYPERPARAMETERS')\n",
    "print('=' * 80)\n",
    "\n",
    "# Check if resuming from previous training\n",
    "checkpoint_path = TRAIN_DIR / 'weights' / 'last.pt'\n",
    "training_log_path = TRAIN_DIR / 'training_log.json'\n",
    "is_resuming = checkpoint_path.exists()\n",
    "\n",
    "if is_resuming:\n",
    "    # Resume training\n",
    "    print('\\n' + '=' * 80)\n",
    "    print('üîÑ RESUMING PREVIOUS TRAINING')\n",
    "    print('=' * 80)\n",
    "    print(f'Checkpoint: {checkpoint_path}')\n",
    "    \n",
    "    # Load training log if available\n",
    "    if training_log_path.exists():\n",
    "        with open(training_log_path, 'r', encoding='utf-8') as f:\n",
    "            training_log = json.load(f)\n",
    "        \n",
    "        print(f'\\nüìä Previous Training Summary:')\n",
    "        print(f\"  Started: {training_log.get('start_time', 'N/A')}\")\n",
    "        if 'last_epoch' in training_log:\n",
    "            print(f\"  Last Epoch: {training_log['last_epoch']}\")\n",
    "        if 'best_map50' in training_log:\n",
    "            print(f\"  Best mAP@0.5: {training_log['best_map50']:.4f}\")\n",
    "        if 'last_checkpoint' in training_log:\n",
    "            print(f\"  Last Checkpoint: {training_log['last_checkpoint']}\")\n",
    "    \n",
    "    print(f'\\n‚û°Ô∏è  Resuming training from checkpoint')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    # Load model from checkpoint\n",
    "    print(f'\\nüì¶ Loading model from checkpoint: {checkpoint_path}')\n",
    "    final_model = YOLO(str(checkpoint_path))\n",
    "    model_to_train = str(checkpoint_path)\n",
    "    resume_training = True\n",
    "    \n",
    "else:\n",
    "    # Start new training\n",
    "    print(f'\\nüì¶ Loading base model: {MODEL_NAME}')\n",
    "    final_model = YOLO(str(model_path))\n",
    "    model_to_train = str(model_path)\n",
    "    resume_training = False\n",
    "    \n",
    "    # Initialize training log\n",
    "    training_log = {\n",
    "        'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model': MODEL_NAME,\n",
    "        'dataset': YOLO_DATASET_ROOT.name,\n",
    "        'config_mode': 'default' if USE_DEFAULT_CONFIG else 'tuned',\n",
    "        'tuning_run': TUNING_RUN_NAME if not USE_DEFAULT_CONFIG else None,\n",
    "        'best_hyperparameters': best_params,\n",
    "        'epochs': EPOCHS_FINAL_TRAINING,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'image_size': IMAGE_SIZE\n",
    "    }\n",
    "\n",
    "# Prepare training parameters\n",
    "# Note: Fixed parameters (not part of optimization) are always included\n",
    "# Optimization parameters are added via **best_params (empty if using defaults)\n",
    "final_training_params = {\n",
    "    # ============================================================================\n",
    "    # FIXED PARAMETERS - Always passed, not part of hyperparameter optimization\n",
    "    # ============================================================================\n",
    "    'data': str(DATA_YAML_PATH),              # Dataset configuration file\n",
    "    'epochs': EPOCHS_FINAL_TRAINING,          # Number of training epochs\n",
    "    'batch': BATCH_SIZE,                       # Batch size\n",
    "    'imgsz': IMAGE_SIZE,                       # Input image size\n",
    "    'device': device,                          # Training device (cuda/cpu)\n",
    "    'project': str(TRAIN_DIR.parent),         # Project directory\n",
    "    'name': TRAIN_DIR.name,                    # Run name\n",
    "    'exist_ok': True,                          # Overwrite existing project\n",
    "    'patience': ModelConfig.DEFAULT_PATIENCE,  # Early stopping patience\n",
    "    'save_period': ModelConfig.DEFAULT_SAVE_PERIOD,  # Save checkpoint frequency\n",
    "    'workers': ModelConfig.DEFAULT_WORKERS,    # Number of data loading workers\n",
    "    'verbose': True,                           # Verbose output\n",
    "    'seed': 42,                                # Random seed for reproducibility\n",
    "    'close_mosaic': ModelConfig.CLOSE_MOSAIC_EPOCHS,  # Disable mosaic in final epochs\n",
    "    'resume': resume_training,                 # Resume from checkpoint if exists\n",
    "    'cache': ModelConfig.DEFAULT_CACHE,        # Cache images for faster training\n",
    "    'val': ModelConfig.DEFAULT_VAL,            # Run validation during training\n",
    "    \n",
    "    # ============================================================================\n",
    "    # OPTIMIZATION PARAMETERS - From tuning (if USE_DEFAULT_CONFIG=False)\n",
    "    # ============================================================================\n",
    "    # Parameters like: lr0, lrf, momentum, weight_decay, warmup_epochs, etc.\n",
    "    **best_params  # Empty dict if USE_DEFAULT_CONFIG=True, tuned params otherwise\n",
    "}\n",
    "\n",
    "print(f'\\nüöÄ {\"Resuming\" if resume_training else \"Starting\"} training...')\n",
    "print(f'  Configuration: {\"Default YOLO\" if USE_DEFAULT_CONFIG else \"Tuned Hyperparameters\"}')\n",
    "print(f'  Epochs: {final_training_params[\"epochs\"]}')\n",
    "print(f'  Batch Size: {final_training_params[\"batch\"]}')\n",
    "print(f'  Dataset: {DATA_YAML_PATH}')\n",
    "print(f'  Device: {device}')\n",
    "print(f'  Resume: {resume_training}')\n",
    "\n",
    "if best_params:\n",
    "    print('\\nüìä Applied Hyperparameters:')\n",
    "    for key, value in sorted(best_params.items()):\n",
    "        if isinstance(value, float):\n",
    "            print(f'  {key:20s}: {value:.6f}')\n",
    "        else:\n",
    "            print(f'  {key:20s}: {value}')\n",
    "else:\n",
    "    print('\\nüìä Using YOLO default hyperparameters (no custom values)')\n",
    "\n",
    "print('\\nThis may take a while. Training progress will be displayed below.')\n",
    "print('=' * 80)\n",
    "\n",
    "USE_WANDB = False\n",
    "# Initialize W&B for final training\n",
    "if USE_WANDB:\n",
    "    try:\n",
    "        wandb_config = {\n",
    "            'model': MODEL_NAME,\n",
    "            'dataset': YOLO_DATASET_ROOT.name,\n",
    "            'phase': 'final_training',\n",
    "            'config_mode': 'default' if USE_DEFAULT_CONFIG else 'tuned',\n",
    "            'tuning_run': TUNING_RUN_NAME if not USE_DEFAULT_CONFIG else None,\n",
    "            'epochs': final_training_params['epochs'],\n",
    "            'batch_size': final_training_params['batch'],\n",
    "            'resume': resume_training,\n",
    "            **best_params\n",
    "        }\n",
    "        \n",
    "        wandb_training_run = wandb.init(\n",
    "            project=WANDB_PROJECT_TRAINING,\n",
    "            name=RUN_NAME_TRAINING,\n",
    "            id=training_log.get('wandb_run_id') if is_resuming else None,\n",
    "            resume='allow' if is_resuming else None,\n",
    "            config=wandb_config,\n",
    "            group='final-training',\n",
    "            tags=['final', 'optimized' if not USE_DEFAULT_CONFIG else 'default', MODEL_NAME, YOLO_DATASET_ROOT.name]\n",
    "        )\n",
    "        \n",
    "        # Save W&B run ID for future resume\n",
    "        if not is_resuming:\n",
    "            training_log['wandb_run_id'] = wandb_training_run.id\n",
    "            with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(training_log, f, indent=2)\n",
    "        \n",
    "        print(f'‚úì W&B initialized: {WANDB_PROJECT_TRAINING}/{RUN_NAME_TRAINING}')\n",
    "    except Exception as wandb_error:\n",
    "        print(f'‚ö†Ô∏è  Could not initialize W&B: {wandb_error}')\n",
    "        wandb_training_run = None\n",
    "else:\n",
    "    wandb_training_run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df0bc9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.233 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.231 üöÄ Python-3.10.12 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12282MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/adminai/src-code/CV/project_repo/tmp/yolo11s/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=70, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0014266301191773261, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.06839573122710534, mode=train, model=/home/adminai/src-code/CV/project_repo/models/yolo11s/yolo11s.pt, momentum=0.9694581216785425, mosaic=0.879214287562742, multi_scale=False, name=yolo11s_train_20251201_081829, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/home/adminai/src-code/CV/project_repo/tune_train/training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829, save_frames=False, save_json=False, save_period=3, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.06052637637356499, warmup_epochs=3, warmup_momentum=0.895636626196151, weight_decay=0.0005408962177381937, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    823278  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
      "YOLO11s summary: 181 layers, 9,431,662 parameters, 9,431,646 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 182.1¬±63.7 MB/s, size: 65.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited/labels/train.cache... 29974 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 29974/29974 61.4Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited/images/train/75055858-7d04a650.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 136.0¬±31.8 MB/s, size: 41.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 17.2Mit/s 0.0ss\n",
      "Plotting labels to /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0014266301191773261, momentum=0.9694581216785425) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005408962177381937), 87 bias(decay=0.0)\n",
      "Image sizes 768 train, 768 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829\u001b[0m\n",
      "Starting training for 70 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/70      9.89G      1.445       1.22      1.066        133        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.6it/s 5:34<0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.8s<0.1s\n",
      "                   all      10000     185578      0.638      0.388      0.423       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/70        10G      1.356     0.9158      1.009        233        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.8it/s 5:21<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.7it/s 40.6s<0.1s\n",
      "                   all      10000     185578      0.639       0.41      0.445      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/70         9G      1.358     0.9028      1.007        187        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:18<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.3it/s 42.6s<0.2s\n",
      "                   all      10000     185578       0.64      0.406       0.44       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/70      9.21G      1.373     0.9119      1.013        303        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.8it/s 40.2s<0.1s\n",
      "                   all      10000     185578       0.64      0.415      0.442      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/70      8.32G      1.363      0.891      1.008        141        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.8s<0.1s\n",
      "                   all      10000     185578      0.673      0.427      0.466      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/70      9.97G      1.353     0.8759      1.004        189        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 38.9s<0.1s\n",
      "                   all      10000     185578      0.667      0.443      0.478      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/70      9.78G      1.343     0.8616          1        182        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.5it/s 41.5s<0.1s\n",
      "                   all      10000     185578      0.678      0.444      0.486       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/70      8.53G      1.338     0.8523     0.9977        230        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.8s<0.1s\n",
      "                   all      10000     185578      0.684      0.445      0.486      0.271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/70      11.3G      1.329     0.8446     0.9959        306        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:17<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.3it/s 37.9s<0.1s\n",
      "                   all      10000     185578      0.677      0.455      0.491      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/70      9.35G      1.327      0.838     0.9935        228        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 39.0s<0.1s\n",
      "                   all      10000     185578      0.699      0.463      0.503      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/70      9.36G      1.322     0.8319     0.9917        125        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 39.1s<0.1s\n",
      "                   all      10000     185578      0.607      0.449      0.505      0.284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/70      7.53G      1.316     0.8233     0.9897        213        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.6s<0.1s\n",
      "                   all      10000     185578        0.6      0.461      0.507      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/70      9.99G      1.315     0.8226     0.9876        273        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.2it/s 38.4s<0.1s\n",
      "                   all      10000     185578      0.594      0.468      0.512      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/70      7.51G      1.311     0.8165     0.9866        256        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:13<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.7s<0.1s\n",
      "                   all      10000     185578      0.708      0.467      0.515      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/70      9.37G      1.304     0.8094     0.9844        285        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 39.0s<0.1s\n",
      "                   all      10000     185578      0.701      0.477      0.521      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/70       9.2G      1.303      0.806     0.9833        254        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 39.4s<0.1s\n",
      "                   all      10000     185578      0.706      0.477      0.524      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/70       8.4G      1.301     0.8025     0.9827        152        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 39.4s<0.1s\n",
      "                   all      10000     185578      0.651      0.504       0.53      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/70      8.03G      1.298     0.7978     0.9807        132        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.4s<0.1s\n",
      "                   all      10000     185578      0.607      0.484       0.53      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/70       8.3G      1.297     0.7954     0.9801        231        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 39.0s<0.1s\n",
      "                   all      10000     185578      0.705      0.483      0.529      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/70      9.09G      1.295     0.7927     0.9798        200        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.4s<0.1s\n",
      "                   all      10000     185578      0.713      0.484      0.533      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/70      9.48G       1.29       0.79      0.978        196        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.9s<0.1s\n",
      "                   all      10000     185578      0.587      0.501      0.535      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/70      8.82G      1.288      0.786     0.9782        296        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 38.9s<0.1s\n",
      "                   all      10000     185578      0.613       0.49      0.536      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/70      7.83G      1.286     0.7827     0.9758        205        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.7s<0.1s\n",
      "                   all      10000     185578      0.618      0.482      0.536      0.307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/70      9.16G      1.284     0.7792     0.9759        141        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.8it/s 40.2s<0.1s\n",
      "                   all      10000     185578      0.617      0.491      0.538      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/70      8.56G      1.283     0.7762     0.9749        131        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.8it/s 40.4s<0.1s\n",
      "                   all      10000     185578      0.638      0.496      0.542      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/70      9.41G      1.279     0.7735     0.9739        234        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.6s<0.1s\n",
      "                   all      10000     185578      0.647      0.493      0.543      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/70       7.8G      1.276     0.7699     0.9727        337        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 71% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ 221/313 9.3it/s 26.7s<9.9ssWARNING ‚ö†Ô∏è NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.6it/s 41.0s<0.1s\n",
      "                   all      10000     185578      0.649      0.491      0.546      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/70      9.11G      1.275     0.7681      0.972        198        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.8s<0.1s\n",
      "                   all      10000     185578      0.641        0.5      0.545      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/70      7.72G       1.27     0.7652     0.9706        186        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 38.9s<0.1s\n",
      "                   all      10000     185578       0.64      0.496      0.546      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/70      8.92G      1.272     0.7624     0.9706        256        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.8s<0.1s\n",
      "                   all      10000     185578      0.634      0.499      0.547      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/70      8.91G      1.271     0.7612     0.9705        189        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.9s<0.1s\n",
      "                   all      10000     185578      0.632      0.501      0.549      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/70      9.13G      1.267     0.7565     0.9689        192        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.8s<0.1s\n",
      "                   all      10000     185578      0.635      0.502      0.549      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/70      9.82G      1.265     0.7558     0.9681        244        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.4s<0.1s\n",
      "                   all      10000     185578       0.64      0.501       0.55      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/70      8.42G      1.263     0.7511     0.9677        179        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 70% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ 218/313 9.1it/s 24.4s<10.5sWARNING ‚ö†Ô∏è NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.4s<0.1s\n",
      "                   all      10000     185578      0.638      0.502       0.55      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/70      8.72G       1.26     0.7487     0.9673        170        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.2it/s 38.4s<0.1s\n",
      "                   all      10000     185578      0.634      0.503      0.551      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/70      8.94G      1.261     0.7479     0.9657        155        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.4s<0.1s\n",
      "                   all      10000     185578      0.637      0.502       0.55      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/70       9.4G       1.26     0.7454     0.9654        162        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.4s<0.1s\n",
      "                   all      10000     185578      0.637      0.502       0.55      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/70      9.03G      1.258     0.7446     0.9641        152        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.7s<0.1s\n",
      "                   all      10000     185578       0.64      0.502       0.55      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/70      8.01G      1.255      0.742     0.9648        124        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 39.0s<0.1s\n",
      "                   all      10000     185578      0.639      0.503       0.55      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/70      9.77G      1.253     0.7396     0.9632        301        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.1it/s 38.7s<0.1s\n",
      "                   all      10000     185578       0.64      0.502       0.55      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/70      10.8G      1.251     0.7357      0.963        292        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.4s<0.1s\n",
      "                   all      10000     185578       0.64      0.502       0.55      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/70      8.41G      1.251     0.7341     0.9618        152        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 39.0s<0.1s\n",
      "                   all      10000     185578       0.64      0.501      0.551      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/70      8.48G       1.25     0.7339     0.9616        285        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 38.9s<0.1s\n",
      "                   all      10000     185578      0.641        0.5       0.55      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/70      10.3G      1.248     0.7297      0.961        231        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.4s<0.1s\n",
      "                   all      10000     185578      0.642      0.499      0.551      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/70         8G      1.245     0.7266     0.9593        230        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.5s<0.1s\n",
      "                   all      10000     185578      0.639      0.501       0.55      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/70      9.31G      1.245      0.725     0.9594        280        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.8s<0.1s\n",
      "                   all      10000     185578      0.642      0.499       0.55      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/70      10.4G      1.241     0.7223     0.9581        176        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.8it/s 40.2s<0.1s\n",
      "                   all      10000     185578      0.635      0.504       0.55      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/70      8.51G      1.238     0.7192     0.9573        299        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.8it/s 39.9s<0.1s\n",
      "                   all      10000     185578      0.637      0.504      0.551      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/70      9.18G      1.242     0.7201     0.9584        225        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.8s<0.1s\n",
      "                   all      10000     185578      0.638      0.503      0.551      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/70      9.68G      1.235     0.7153     0.9567        171        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.8it/s 40.3s<0.1s\n",
      "                   all      10000     185578      0.637      0.504      0.551      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      51/70      8.99G      1.238     0.7136     0.9563        162        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.2it/s 43.2s<0.1s\n",
      "                   all      10000     185578      0.641      0.502      0.551      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      52/70      8.48G      1.233     0.7107     0.9558        226        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.7it/s 40.4s<0.1s\n",
      "                   all      10000     185578      0.642      0.503      0.552      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      53/70      9.68G       1.23     0.7079     0.9538        172        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.6it/s 41.0s<0.1s\n",
      "                   all      10000     185578      0.639      0.505      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      54/70        10G      1.228     0.7051     0.9539        181        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.6it/s 41.0s<0.1s\n",
      "                   all      10000     185578       0.64      0.505      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      55/70      10.2G      1.227     0.7034     0.9529        247        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:15<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.6it/s 41.3s<0.1s\n",
      "                   all      10000     185578      0.643      0.505      0.554      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      56/70      9.12G      1.226     0.6994     0.9522        244        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.5it/s 41.5s<0.1s\n",
      "                   all      10000     185578      0.643      0.505      0.554      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      57/70      9.32G      1.224     0.6988     0.9526        222        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:12<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.1it/s 44.3s<0.1s\n",
      "                   all      10000     185578      0.645      0.504      0.554      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      58/70      8.93G       1.22     0.6933     0.9493        221        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 5.9it/s 5:16<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.5it/s 41.8s<0.1s\n",
      "                   all      10000     185578      0.646      0.503      0.554      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      59/70      10.2G      1.223     0.6943     0.9506        153        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.6it/s 41.4s<0.1s\n",
      "                   all      10000     185578      0.648      0.502      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      60/70      9.57G       1.22     0.6913     0.9502        167        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.0it/s 5:14<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.5it/s 41.6s<0.1s\n",
      "                   all      10000     185578       0.65      0.501      0.553      0.319\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      61/70      5.96G      1.232     0.6679     0.9452        125        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.2it/s 5:03<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.3it/s 42.8s<0.1s\n",
      "                   all      10000     185578      0.646      0.503      0.554      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      62/70      5.96G      1.228     0.6624     0.9431        117        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.3it/s 4:58<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 16% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 51/313 7.5it/s 6.5s<34.8sWARNING ‚ö†Ô∏è NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 6.6it/s 47.1s<0.1s\n",
      "                   all      10000     185578      0.646      0.502      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      63/70      5.96G      1.226      0.658     0.9425        158        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.3it/s 4:57<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.7it/s 40.9s<0.1s\n",
      "                   all      10000     185578      0.646      0.501      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      64/70      5.96G      1.222     0.6553     0.9418         98        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.3it/s 4:57<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 6.7it/s 46.6s<0.1s\n",
      "                   all      10000     185578      0.644      0.501      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      65/70      5.96G       1.22     0.6518     0.9404        105        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.3it/s 4:58<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.4it/s 42.3s<0.1s\n",
      "                   all      10000     185578      0.643      0.501      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      66/70      5.96G      1.216     0.6483     0.9402         79        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.3it/s 4:60<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.3it/s 42.6s<0.1s\n",
      "                   all      10000     185578      0.644        0.5      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      67/70      5.96G      1.214     0.6462     0.9384         61        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.3it/s 4:57<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.3it/s 42.7s<0.1s\n",
      "                   all      10000     185578      0.643        0.5      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      68/70      5.96G      1.212     0.6435      0.938        116        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.2it/s 5:01<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.6it/s 41.4s<0.1s\n",
      "                   all      10000     185578      0.636      0.506      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      69/70      5.98G      1.211     0.6406     0.9376        109        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.3it/s 4:57<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 18% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 57/313 8.3it/s 6.7s<30.8sWARNING ‚ö†Ô∏è NMS time limit 3.600s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 7.9it/s 39.5s<0.1s\n",
      "                   all      10000     185578      0.639      0.506      0.553      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      70/70      5.98G      1.208     0.6385     0.9361        178        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1874/1874 6.2it/s 5:02<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 8.0it/s 39.3s<0.1s\n",
      "                   all      10000     185578       0.64      0.505      0.552      0.317\n",
      "\n",
      "70 epochs completed in 6.897 hours.\n",
      "Optimizer stripped from /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829/weights/last.pt, 19.2MB\n",
      "Optimizer stripped from /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829/weights/best.pt, 19.2MB\n",
      "\n",
      "Validating /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829/weights/best.pt...\n",
      "Ultralytics 8.3.231 üöÄ Python-3.10.12 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12282MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,416,670 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 313/313 6.9it/s 45.2s<0.1s\n",
      "                   all      10000     185578       0.65      0.501      0.553      0.319\n",
      "                person       3220      13265      0.779      0.545      0.653      0.336\n",
      "                 rider        515        649      0.665      0.456      0.489      0.254\n",
      "                   car       9879     102540      0.833      0.704      0.798        0.5\n",
      "                 truck       2689       4247      0.665      0.588      0.636      0.466\n",
      "                   bus       1242       1597      0.679      0.571      0.629       0.49\n",
      "                 train         14         15      0.148     0.0667     0.0375     0.0282\n",
      "                 motor        334        452      0.641      0.439      0.463      0.237\n",
      "                  bike        578       1007      0.594        0.5      0.522      0.267\n",
      "         traffic light       5653      26891      0.748      0.543      0.629      0.245\n",
      "          traffic sign       8221      34915      0.744      0.598      0.677      0.363\n",
      "Speed: 0.1ms preprocess, 1.0ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829\u001b[0m\n",
      "\n",
      "‚úì Training completed successfully!\n",
      "\n",
      "================================================================================\n",
      "TRAINING SUMMARY\n",
      "================================================================================\n",
      "Last Weights: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829/weights/last.pt\n",
      "================================================================================\n",
      "Best Weights: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829/weights/best.pt\n",
      "Training Directory: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251201_081829\n",
      "Start Time: 2025-12-01 08:19:34\n",
      "Configuration: Tuned (yolo11s_finetuned_20251201_tune_20251201_050018)\n",
      "End Time: 2025-12-01 15:14:16\n",
      "Duration: 6:54:41.920102\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "start_time = datetime.now()\n",
    "try:\n",
    "    final_results = final_model.train(**final_training_params)\n",
    "    \n",
    "    # Update training log with completion\n",
    "    training_log['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    training_log['status'] = 'completed'\n",
    "    training_log['duration'] = str(datetime.now() - start_time)\n",
    "    \n",
    "    # Save final metrics\n",
    "    if hasattr(final_results, 'results_dict'):\n",
    "        training_log['final_metrics'] = final_results.results_dict\n",
    "    \n",
    "    # Save updated training log\n",
    "    with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_log, f, indent=2)\n",
    "    \n",
    "    print('\\n‚úì Training completed successfully!')\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print('\\n‚ö†Ô∏è  Training interrupted by user')\n",
    "    print(f'üíæ Progress saved to: {TRAIN_DIR}')\n",
    "    print(f'   - Last checkpoint: {checkpoint_path}')\n",
    "    print(f'   - Training log: {training_log_path}')\n",
    "    print(f'\\nüîÑ To resume: Simply re-run this notebook')\n",
    "    \n",
    "    # Update training log\n",
    "    training_log['last_interrupt'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    training_log['status'] = 'interrupted'\n",
    "    training_log['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_log, f, indent=2)\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'\\n‚ùå Training failed with error: {e}')\n",
    "    training_log['status'] = 'failed'\n",
    "    training_log['error'] = str(e)\n",
    "    training_log['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_log, f, indent=2)\n",
    "    raise\n",
    "    \n",
    "finally:\n",
    "    if USE_WANDB and wandb_training_run is not None:\n",
    "        wandb_training_run.finish()\n",
    "        print('‚úì W&B run finished')\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('TRAINING SUMMARY')\n",
    "print('=' * 80)\n",
    "\n",
    "\n",
    "print(f'Last Weights: {TRAIN_DIR / \"weights\" / \"last.pt\"}')\n",
    "\n",
    "print('=' * 80)\n",
    "print(f'Best Weights: {TRAIN_DIR / \"weights\" / \"best.pt\"}')\n",
    "\n",
    "print(f'Training Directory: {TRAIN_DIR}') \n",
    "print(f'Start Time: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Configuration: {\"Default YOLO\" if USE_DEFAULT_CONFIG else f\"Tuned ({TUNING_RUN_NAME})\"}') \n",
    "print(f'End Time: {end_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Duration: {duration}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b8289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Running final validation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get final validation metrics\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Running final validation...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m final_val_results \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_model\u001b[49m\u001b[38;5;241m.\u001b[39mval(\n\u001b[1;32m      4\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(DATA_YAML_PATH),\n\u001b[1;32m      5\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(TRAIN_DIR),\n\u001b[1;32m      6\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_val\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m final_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap50\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(final_val_results\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap50),\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap50_95\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(final_val_results\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap),\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(final_val_results\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmp),\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(final_val_results\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmr),\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Final Model Performance:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Get final validation metrics\n",
    "print('\\nüìä Running final validation...')\n",
    "final_val_results = final_model.val(\n",
    "    data=str(DATA_YAML_PATH),\n",
    "    project=str(TRAIN_DIR),\n",
    "    name='final_val',\n",
    ")\n",
    "\n",
    "final_metrics = {\n",
    "    'map50': float(final_val_results.box.map50),\n",
    "    'map50_95': float(final_val_results.box.map),\n",
    "    'precision': float(final_val_results.box.mp),\n",
    "    'recall': float(final_val_results.box.mr),\n",
    "}\n",
    "\n",
    "print('\\nüìä Final Model Performance:')\n",
    "print(f\"  mAP@0.5: {final_metrics['map50']:.4f}\")\n",
    "print(f\"  mAP@0.5:0.95: {final_metrics['map50_95']:.4f}\")\n",
    "print(f\"  Precision: {final_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {final_metrics['recall']:.4f}\")\n",
    "\n",
    "# Update training log with final metrics\n",
    "training_log['final_metrics'] = final_metrics\n",
    "training_log['best_model_path'] = str(TRAIN_DIR / 'weights' / 'best.pt')\n",
    "training_log['last_model_path'] = str(TRAIN_DIR / 'weights' / 'last.pt')\n",
    "\n",
    "# Save final training log\n",
    "with open(training_log_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_log, f, indent=2)\n",
    "\n",
    "print(f'\\nüíæ Training log saved: {training_log_path}')\n",
    "\n",
    "# Compare with tuning results if available\n",
    "if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "    tuning_best_map = tuning_metadata.get('best_map50', 0)\n",
    "    improvement = final_metrics['map50'] - tuning_best_map\n",
    "    print('\\nüìà Improvement vs Best Tuning Trial:')\n",
    "    print(f\"  Best Tuning mAP@0.5: {tuning_best_map:.4f}\")\n",
    "    print(f\"  Final Model mAP@0.5: {final_metrics['map50']:.4f}\")\n",
    "\n",
    "    print(f\"  Improvement: {improvement:+.4f} ({improvement/tuning_best_map*100:+.2f}%)\")\n",
    "    print('=' * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b00a39",
   "metadata": {},
   "source": [
    "## 8. Save Final Model and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d959bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING FINAL OPTIMIZED MODEL\n",
      "================================================================================\n",
      "\n",
      "‚úì Final model saved to: /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201/yolo11s_finetuned_20251201.pt\n",
      "  Size: 18.3 MB\n",
      "‚úì Model metadata saved to: /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201/yolo11s_finetuned_20251201_metadata.json\n",
      "\n",
      "üì¶ Final Model Package:\n",
      "  Model: /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201/yolo11s_finetuned_20251201.pt\n",
      "  Metadata: /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201/yolo11s_finetuned_20251201_metadata.json\n",
      "  Training Log: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251130_075906/training_log.json\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAVE FINAL OPTIMIZED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('SAVING FINAL OPTIMIZED MODEL')\n",
    "print('=' * 80)\n",
    "\n",
    "date_stamp = datetime.now().strftime('%Y%m%d')\n",
    "finetuned_model_name = f'{MODEL_NAME}_finetuned_{date_stamp}'\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "model_save_dir = BASE_DIR / 'models' / finetuned_model_name\n",
    "model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define paths for saving\n",
    "final_model_path = model_save_dir / f'{finetuned_model_name}.pt'\n",
    "metadata_path = model_save_dir / f'{finetuned_model_name}_metadata.json'\n",
    "\n",
    "# Copy best weights from training directory\n",
    "# Note: TRAIN_DIR already includes RUN_NAME_TRAINING\n",
    "weights_path = TRAIN_DIR / 'weights' / 'best.pt'\n",
    "\n",
    "if weights_path.exists():\n",
    "    shutil.copy(weights_path, final_model_path)\n",
    "    print(f'\\n‚úì Final model saved to: {final_model_path}')\n",
    "    print(f'  Size: {final_model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "else:\n",
    "    print(f'\\n‚ö†Ô∏è  Best weights not found at: {weights_path}')\n",
    "    print('  Attempting to save current model state...')\n",
    "    try:\n",
    "        # Save current model state if weights not found\n",
    "        final_model.save(str(final_model_path))\n",
    "        print(f'‚úì Model saved to: {final_model_path}')\n",
    "    except Exception as save_error:\n",
    "        print(f'‚ö†Ô∏è  Error saving model: {save_error}')\n",
    "\n",
    "# Prepare optimization metadata\n",
    "optimization_meta = {\n",
    "    'tuning_run': TUNING_RUN_NAME,\n",
    "    'tuning_run_path': str(TUNE_DIR),\n",
    "}\n",
    "\n",
    "# Add tuning details if available\n",
    "if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "    optimization_meta.update({\n",
    "        'n_trials': tuning_metadata.get('total_trials', 'N/A'),\n",
    "        'completed_trials': tuning_metadata.get('completed_trials', 'N/A'),\n",
    "        'best_trial': tuning_metadata.get('best_trial', 'N/A'),\n",
    "        'best_trial_map50': tuning_metadata.get('best_map50', 0),\n",
    "        'optimization_duration': tuning_metadata.get('optimization_duration', 'N/A'),\n",
    "    })\n",
    "\n",
    "# Calculate improvement if tuning metadata available\n",
    "improvement_value = 0\n",
    "if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "    tuning_best_map = tuning_metadata.get('best_map50', 0)\n",
    "    if tuning_best_map > 0:\n",
    "        improvement_value = float(final_metrics['map50'] - tuning_best_map)\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'finetuned_name': finetuned_model_name,\n",
    "    'model_path': str(final_model_path),\n",
    "    'dataset': str(YOLO_DATASET_ROOT),\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'training_run': RUN_NAME_TRAINING,\n",
    "    'training_run_path': str(TRAIN_DIR),\n",
    "    'optimization': optimization_meta,\n",
    "    'best_hyperparameters': best_params,\n",
    "    'training_params': {\n",
    "        'epochs': EPOCHS_FINAL_TRAINING,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'image_size': IMAGE_SIZE,\n",
    "        'patience': ModelConfig.DEFAULT_PATIENCE,\n",
    "        'save_period': ModelConfig.DEFAULT_SAVE_PERIOD,\n",
    "    },\n",
    "    'final_metrics': final_metrics,\n",
    "    'improvement_vs_tuning': improvement_value,\n",
    "}\n",
    "\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f'‚úì Model metadata saved to: {metadata_path}')\n",
    "print('\\nüì¶ Final Model Package:')\n",
    "print(f'  Model: {final_model_path}')\n",
    "print(f'  Metadata: {metadata_path}')\n",
    "print(f'  Training Log: {training_log_path}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ab57b",
   "metadata": {},
   "source": [
    "## 9. Test Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cfc6346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING FINAL VALIDATION ON TEST SET\n",
      "================================================================================\n",
      "\n",
      "üîç Validation Configuration:\n",
      "   Base Dir: /home/adminai/src-code/CV/project_repo\n",
      "   Dataset: bdd100k_yolo_limited\n",
      "   Model: yolo11s_finetuned_20251201\n",
      "   Expected dataset path: /home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited/data.yaml\n",
      "   Expected model path: /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201/yolo11s_finetuned_20251201.pt\n",
      "   Actual model path: /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201/yolo11s_finetuned_20251201.pt\n",
      "‚úì Device: cuda\n",
      "  GPU: NVIDIA GeForce RTX 4070 SUPER\n",
      "‚úì W&B logging enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  W&B initialization error: API key must be at least 40 characters long, yours was 5\n",
      "  Continuing without W&B tracking...\n",
      "‚úì Dataset loaded\n",
      "  Total images: 20000\n",
      "  Images with labels: 20000\n",
      "  Label files: 20000\n",
      "\n",
      "‚úì Metadata loaded: test_metadata.json\n",
      "  Images with attributes: 20000\n",
      "‚úì Model loaded from /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201/yolo11s_finetuned_20251201.pt\n",
      "YOLO11s summary: 181 layers, 9,431,662 parameters, 0 gradients, 21.6 GFLOPs\n",
      "\n",
      "üìä Model Information:\n",
      "  Model: yolo11s_finetuned_20251201\n",
      "  Classes in model: 10\n",
      "  Task: detect\n",
      "  Parameters: 9.4M\n",
      "  Model Size: 18.3 MB\n",
      "  FLOPs (640x640): 21.57 GFLOPs\n",
      "  Model Size: 18.3 MB\n",
      "\n",
      "================================================================================\n",
      "PHASE 1: OFFICIAL YOLO VALIDATION (for accurate metrics)\n",
      "================================================================================\n",
      "WARNING ‚ö†Ô∏è 'save_hybrid' is deprecated and will be removed in the future.\n",
      "Ultralytics 8.3.231 üöÄ Python-3.10.12 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12282MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,416,670 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 120.4¬±86.7 MB/s, size: 47.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited/labels/test... 20000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 20000/20000 1.8Kit/s 10.9s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited/images/test/e6f10c58-c46de527.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited/labels/test.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 625/625 6.7it/s 1:33<0.1ss\n",
      "                   all      20000     367727      0.645      0.485      0.531      0.295\n",
      "                person       6213      24650      0.775      0.522      0.619      0.307\n",
      "                 rider       1004       1294      0.628      0.438      0.477      0.235\n",
      "                   car      19776     205149      0.826      0.701      0.776      0.483\n",
      "                 truck       5500       8704      0.661      0.567      0.618      0.446\n",
      "                   bus       2459       3217      0.637      0.538       0.57      0.435\n",
      "                 train         26         28      0.209     0.0714      0.083     0.0272\n",
      "                 motor        640        841      0.653      0.474       0.48      0.237\n",
      "                  bike       1182       1998      0.569      0.483      0.479      0.226\n",
      "         traffic light      11051      52840      0.741      0.503      0.578      0.219\n",
      "          traffic sign      16432      69006      0.747      0.548      0.633      0.334\n",
      "Speed: 0.2ms preprocess, 1.4ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/adminai/src-code/CV/project_repo/yolo_test/analysis_runs/yolo11s_finetuned_20251201_testing_20251201_070038/yolo_validation\u001b[0m\n",
      "\n",
      "‚úì Official validation complete in 106.69s\n",
      "‚úì Confusion matrix shape: (11, 11)\n",
      "\n",
      "‚úì Official Metrics:\n",
      "  - Precision: 0.6446\n",
      "  - Recall: 0.4846\n",
      "  - mAP@0.5: 0.5314\n",
      "  - mAP@0.5:0.95: 0.2949\n",
      "\n",
      "================================================================================\n",
      "PHASE 2: PER-IMAGE PREDICTION (for attribute-based analysis)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "COLLECTING PER-IMAGE PREDICTIONS FOR DETAILED ANALYSIS\n",
      "================================================================================\n",
      "‚úì Found 20000 images to evaluate\n",
      "‚úì Model device: cuda\n",
      "‚úì IoU threshold: 0.5\n",
      "‚úì Collecting per-image details for attribute-based analysis...\n",
      "‚úì Tracking 10 classes\n",
      "  Model classes: ['person', 'rider', 'car', 'truck', 'bus', 'train', 'motor', 'bike', 'traffic light', 'traffic sign']\n",
      "\n",
      "================================================================================\n",
      "PROCESSING IMAGES\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:   3%|‚ñé         | 504/20000 [00:14<12:26, 26.12img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 2.050s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:  10%|‚ñà         | 2006/20000 [00:56<06:29, 46.21img/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 2000/20000 images | Avg: 13.8ms/img | ETA: 249.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:  20%|‚ñà‚ñà        | 4008/20000 [01:47<05:38, 47.28img/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 4000/20000 images | Avg: 12.9ms/img | ETA: 206.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:  30%|‚ñà‚ñà‚ñà       | 6004/20000 [02:33<04:37, 50.45img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 6000/20000 images | Avg: 12.4ms/img | ETA: 172.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:  40%|‚ñà‚ñà‚ñà‚ñà      | 8008/20000 [03:20<04:16, 46.80img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 8000/20000 images | Avg: 12.3ms/img | ETA: 148.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 10005/20000 [04:09<03:09, 52.77img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 10000/20000 images | Avg: 12.2ms/img | ETA: 122.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 12007/20000 [04:52<02:51, 46.62img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 12000/20000 images | Avg: 12.1ms/img | ETA: 96.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 14005/20000 [05:38<02:28, 40.40img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 14000/20000 images | Avg: 11.9ms/img | ETA: 71.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 16005/20000 [06:37<01:21, 49.06img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 16000/20000 images | Avg: 12.2ms/img | ETA: 49.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 18006/20000 [07:25<00:59, 33.41img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 18000/20000 images | Avg: 12.3ms/img | ETA: 24.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting image details: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20000/20000 [08:15<00:00, 40.36img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 20000/20000 images | Avg: 12.4ms/img | ETA: 0.0s\n",
      "\n",
      "================================================================================\n",
      "PER-IMAGE COLLECTION COMPLETE\n",
      "================================================================================\n",
      "‚úì Total images processed: 20000\n",
      "‚úì Collection time: 495.53s\n",
      "‚úì Average time per image: 0.025s\n",
      "================================================================================\n",
      "\n",
      "\n",
      "‚úì Hybrid validation complete. Official validation time: 106.69s\n",
      "\n",
      "‚úì Calculated per-class metrics from confusion matrix:\n",
      "  Total TP: 238873, FP: 128854, FN: 58246\n",
      "\n",
      "================================================================================\n",
      "OFFICIAL YOLO VALIDATION RESULTS\n",
      "================================================================================\n",
      "Precision (mean): 0.6446\n",
      "Recall (mean):    0.4846\n",
      "mAP@0.5:          0.5314\n",
      "mAP@0.5:0.95:     0.2949\n",
      "Fitness:          0.2949\n",
      "\n",
      "‚ö° Performance Metrics:\n",
      "  Total Time: 106.69s\n",
      "  Average Inference Time: 2140.51 ms per image\n",
      "  FPS (Frames Per Second): 467.18\n",
      "================================================================================\n",
      "(Green = Correct Predictions, Red = Incorrect Predictions, White = No Predictions)\n",
      "‚úì Copied confusion matrix from YOLO validation\n",
      "‚úì Copied normalized confusion matrix from YOLO validation\n",
      "\n",
      "================================================================================\n",
      "GENERATING SAMPLE COMPARISONS\n",
      "================================================================================\n",
      "\n",
      "Generating 6 high-resolution comparison figures with attributes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating comparisons: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generated 6 comparison images\n",
      "  Saved to: /home/adminai/src-code/CV/project_repo/yolo_test/analysis_runs/yolo11s_finetuned_20251201_testing_20251201_070038/sample_comparisons\n",
      "\n",
      "================================================================================\n",
      "GENERATING DETAILED PERFORMANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GENERATING COMPREHENSIVE FAILURE ANALYSIS\n",
      "Analyzing relationship between attributes and prediction accuracy...\n",
      "================================================================================\n",
      "\n",
      "üîç Attempting to load training metadata from: /home/adminai/src-code/CV/project_repo/bdd100k_yolo_limited/representative_json/train_metadata.json\n",
      "  File exists: True\n",
      "\n",
      "Loading training split metadata for exposure analysis...\n",
      "  Processing 29974 training images...\n",
      "‚úì Training metadata loaded: 29974 images, 629238 objects\n",
      "  - Classes found in training data: 10\n",
      "  - Sample class counts: {9: 114446, 2: 327660, 4: 8070}\n",
      "\n",
      "================================================================================\n",
      "ANALYZING FAILURES BY ATTRIBUTES\n",
      "================================================================================\n",
      "‚úì Analysis results will be saved to: /home/adminai/src-code/CV/project_repo/yolo_test/analysis_runs/yolo11s_finetuned_20251201_testing_20251201_070038/performance_analysis\n",
      "‚úì Training metadata loaded with 10 classes\n",
      "Processing 20000 images for attribute analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20000/20000 [00:04<00:00, 4176.64img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Analysis complete:\n",
      "  - Total images: 20000\n",
      "  - Total objects: 367728\n",
      "  - Matched objects: 293551\n",
      "  - Overall accuracy: 79.83%\n",
      "\n",
      "‚úì Saving analysis results to CSV files...\n",
      "‚úì Saved 10 CSV files to /home/adminai/src-code/CV/project_repo/yolo_test/analysis_runs/yolo11s_finetuned_20251201_testing_20251201_070038/performance_analysis\n",
      "\n",
      "‚úì Attribute-based analysis complete\n",
      "  Total images analyzed: 20000\n",
      "  Overall accuracy: 79.83%\n",
      "\n",
      "üìä Training Exposure Analysis Status:\n",
      "  - train_class_counts populated: True (10 classes)\n",
      "  - df_train_test populated: True (10 rows)\n",
      "  - Sample df_train_test rows:\n",
      " class_id class_name  train_count  test_count  test_accuracy  train_test_ratio\n",
      "        0     person        56678       24650       0.762150          2.299310\n",
      "        1      rider         4346        1294       0.549459          3.358578\n",
      "        2        car       327660      205150       0.832820          1.597173\n",
      "  ‚úì Training exposure charts will be generated\n",
      "\n",
      "‚úì Analysis charts will be saved to: /home/adminai/src-code/CV/project_repo/yolo_test/analysis_runs/yolo11s_finetuned_20251201_testing_20251201_070038/performance_analysis\n",
      "\n",
      " Generating accuracy analysis charts...\n",
      "\n",
      "üîç Training Exposure Charts Generation Check:\n",
      "  - train_class_counts: 10 classes\n",
      "  - df_train_test: 10 rows\n",
      "  - Condition (not df_train_test.empty and train_class_counts): {9: 114446, 2: 327660, 4: 8070, 0: 56678, 8: 91121, 6: 3002, 3: 16992, 7: 6787, 1: 4346, 5: 136}\n",
      "  ‚úì Generated: accuracy_vs_training_exposure.png\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "Overall Accuracy: 79.83%\n",
      "Total Images: 20000\n",
      "Expected Objects: 367728\n",
      "Matched Objects: 293551\n",
      "\n",
      "Weakest Weather Conditions:\n",
      "  - overcast: 78.45% (2568 images)\n",
      "  - partly cloudy: 79.15% (1441 images)\n",
      "  - clear: 79.83% (10756 images)\n",
      "\n",
      "Weakest Scenes:\n",
      "  - highway: 78.24% (5069 images)\n",
      "  - city street: 79.78% (12288 images)\n",
      "  - residential: 82.77% (2382 images)\n",
      "\n",
      "Weakest Times of Day:\n",
      "  - dawn/dusk: 79.29% (1476 images)\n",
      "  - daytime: 79.44% (10446 images)\n",
      "  - night: 80.55% (8036 images)\n",
      "\n",
      "Accuracy by Object Size (Scale/Distance):\n",
      "  - small: 77.41% (321502 objects)\n",
      "  - medium: 96.61% (33242 objects)\n",
      "  - large: 96.63% (12984 objects)\n",
      "\n",
      "Train-Test Comparison (Classes with Lowest Accuracy):\n",
      "  - train: 21.43% accuracy | Train: 136 objs, Test: 28 objs | Ratio: 4.9x\n",
      "  - rider: 54.95% accuracy | Train: 4346 objs, Test: 1294 objs | Ratio: 3.4x\n",
      "  - motor: 59.93% accuracy | Train: 3002 objs, Test: 841 objs | Ratio: 3.6x\n",
      "\n",
      "‚úì Comprehensive failure analysis complete\n",
      "  - Charts saved: 10\n",
      "  - CSV files saved: 12\n",
      "  - JSON summary: /home/adminai/src-code/CV/project_repo/yolo_test/analysis_runs/yolo11s_finetuned_20251201_testing_20251201_070038/failure_analysis_comprehensive.json\n",
      "================================================================================\n",
      "================================================================================\n",
      "‚úì COMPREHENSIVE REPORT GENERATED (script)\n",
      "================================================================================\n",
      "PDF Report: /home/adminai/src-code/CV/project_repo/yolo_test/analysis_runs/yolo11s_finetuned_20251201_testing_20251201_070038/report.pdf\n",
      "JSON Metrics: /home/adminai/src-code/CV/project_repo/yolo_test/analysis_runs/yolo11s_finetuned_20251201_testing_20251201_070038/metrics_data.json\n",
      "\n",
      "üßπ Cleaning up model from memory...\n",
      "‚úì Model removed from memory\n",
      "\n",
      "üìä Final Validation Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>iou</th>\n",
       "      <th>precision_confusion</th>\n",
       "      <th>recall_confusion</th>\n",
       "      <th>f1_confusion</th>\n",
       "      <th>precision_yolo</th>\n",
       "      <th>recall_yolo</th>\n",
       "      <th>map50</th>\n",
       "      <th>map50_95</th>\n",
       "      <th>params_m</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>fps</th>\n",
       "      <th>status</th>\n",
       "      <th>run_dir</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yolo11s_finetuned_20251201</td>\n",
       "      <td>bdd100k_yolo_limited</td>\n",
       "      <td>test</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.649593</td>\n",
       "      <td>0.803964</td>\n",
       "      <td>0.718581</td>\n",
       "      <td>0.644641</td>\n",
       "      <td>0.484638</td>\n",
       "      <td>0.531374</td>\n",
       "      <td>0.294946</td>\n",
       "      <td>9.431662</td>\n",
       "      <td>18.277308</td>\n",
       "      <td>467.178763</td>\n",
       "      <td>ok</td>\n",
       "      <td>/home/adminai/src-code/CV/project_repo/yolo_te...</td>\n",
       "      <td>{'data': '/home/adminai/src-code/CV/project_re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model_name               dataset split  iou  \\\n",
       "0  yolo11s_finetuned_20251201  bdd100k_yolo_limited  test  0.5   \n",
       "\n",
       "   precision_confusion  recall_confusion  f1_confusion  precision_yolo  \\\n",
       "0             0.649593          0.803964      0.718581        0.644641   \n",
       "\n",
       "   recall_yolo     map50  map50_95  params_m    size_mb         fps status  \\\n",
       "0     0.484638  0.531374  0.294946  9.431662  18.277308  467.178763     ok   \n",
       "\n",
       "                                             run_dir  \\\n",
       "0  /home/adminai/src-code/CV/project_repo/yolo_te...   \n",
       "\n",
       "                                     hyperparameters  \n",
       "0  {'data': '/home/adminai/src-code/CV/project_re...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN FINAL VALIDATION ON TEST SET (ENHANCED)\n",
    "# ============================================================================\n",
    "print('\\n' + '=' * 80)\n",
    "print('RUNNING FINAL VALIDATION ON TEST SET')\n",
    "print('=' * 80)\n",
    "\n",
    "results_summary = []\n",
    "IOU_THRESHOLDS = 0.5  # Could expand to [0.5, 0.55, 0.6] if needed\n",
    "\n",
    "# Verify that the final model exists before validation\n",
    "if not final_model_path.exists():\n",
    "    print(f\"‚ö†Ô∏è  Warning: Final model not found at {final_model_path}\")\n",
    "    print(f\"   Skipping test validation. Please complete training first.\")\n",
    "else:\n",
    "    # Add YOLO test scripts path safely\n",
    "    scrpt_dir = BASE_DIR / \"yolo_test\"\n",
    "    if str(scrpt_dir) not in sys.path:\n",
    "        sys.path.append(str(scrpt_dir))\n",
    "\n",
    "    try:\n",
    "        from run_yolo_detailed_testing_report import run_validation_pipeline\n",
    "\n",
    "        # Important: \n",
    "        # - Datasets are in DATASET_BASE_DIR (can be different in Colab)\n",
    "        # - Models are ALWAYS in BASE_DIR/models/\n",
    "        # \n",
    "        # Validation script uses base_dir for both:\n",
    "        #   - Dataset path: base_dir / dataset_name / data.yaml\n",
    "        #   - Model path: base_dir / models / model_name / model_name.pt\n",
    "        #\n",
    "        # Solution: Copy dataset to BASE_DIR temporarily, or use symlink\n",
    "        \n",
    "        # For Colab: Need to ensure model is accessible\n",
    "        if IS_COLAB:\n",
    "            # Check if dataset exists in BASE_DIR\n",
    "            base_dir_dataset = BASE_DIR / dataset_name\n",
    "            if not (base_dir_dataset / 'data.yaml').exists() and YOLO_DATASET_ROOT.exists():\n",
    "                print(f\"\\nüìÇ Dataset location mismatch detected\")\n",
    "                print(f\"   Dataset is in: {YOLO_DATASET_ROOT}\")\n",
    "                print(f\"   Validation expects: {base_dir_dataset}\")\n",
    "                print(f\"   Creating symbolic link...\")\n",
    "                try:\n",
    "                    import os\n",
    "                    if not base_dir_dataset.exists():\n",
    "                        os.symlink(str(YOLO_DATASET_ROOT), str(base_dir_dataset))\n",
    "                        print(f\"   ‚úì Symbolic link created\")\n",
    "                except Exception as symlink_error:\n",
    "                    print(f\"   ‚ö†Ô∏è  Could not create symlink: {symlink_error}\")\n",
    "                    print(f\"   Validation may fail if dataset path is incorrect\")\n",
    "            \n",
    "            validation_base_dir = BASE_DIR\n",
    "        else:\n",
    "            validation_base_dir = BASE_DIR\n",
    "        \n",
    "        print(f\"\\nüîç Validation Configuration:\")\n",
    "        print(f\"   Base Dir: {validation_base_dir}\")\n",
    "        print(f\"   Dataset: {dataset_name}\")\n",
    "        print(f\"   Model: {finetuned_model_name}\")\n",
    "        print(f\"   Expected dataset path: {validation_base_dir / dataset_name / 'data.yaml'}\")\n",
    "        print(f\"   Expected model path: {validation_base_dir / 'models' / finetuned_model_name / f'{finetuned_model_name}.pt'}\")\n",
    "        print(f\"   Actual model path: {final_model_path}\")\n",
    "        \n",
    "        # Verify paths\n",
    "        expected_model_path = validation_base_dir / 'models' / finetuned_model_name / f'{finetuned_model_name}.pt'\n",
    "        if final_model_path != expected_model_path and not expected_model_path.exists():\n",
    "            print(f\"\\nüì¶ Copying model to expected location...\")\n",
    "            expected_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(final_model_path, expected_model_path)\n",
    "            print(f\"   ‚úì Model copied to {expected_model_path}\")\n",
    "        \n",
    "        result = run_validation_pipeline(\n",
    "            model_name=finetuned_model_name,\n",
    "            dataset_name=dataset_name,\n",
    "            split=\"test\",\n",
    "            iou_threshold=IOU_THRESHOLDS,\n",
    "            base_dir=validation_base_dir,\n",
    "            use_wandb=True,\n",
    "            save_reports=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            include_training_exposure_analysis=True\n",
    "        )\n",
    "        \n",
    "        overall = result[\"metrics\"][\"overall\"]\n",
    "        yolo_overall = result[\"metrics\"][\"yolo_metrics\"]\n",
    "        \n",
    "        results_summary.append({\n",
    "            \"model_name\": finetuned_model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"split\": \"test\",\n",
    "            \"iou\": IOU_THRESHOLDS,\n",
    "            \"precision_confusion\": overall[\"precision\"],\n",
    "            \"recall_confusion\": overall[\"recall\"],\n",
    "            \"f1_confusion\": overall[\"f1\"],\n",
    "            \"precision_yolo\": yolo_overall[\"precision\"],\n",
    "            \"recall_yolo\": yolo_overall[\"recall\"],\n",
    "            \"map50\": yolo_overall[\"map50\"],\n",
    "            \"map50_95\": yolo_overall[\"map50_95\"],\n",
    "            \"params_m\": result[\"model_info\"][\"params\"] / 1e6,\n",
    "            \"size_mb\": result[\"model_info\"][\"size(MB)\"],\n",
    "            \"fps\": result[\"metrics\"][\"fps\"],\n",
    "            \"status\": \"ok\",\n",
    "            \"run_dir\": str(result[\"run_dir\"]),\n",
    "            \"hyperparameters\": final_training_params,  # traceable\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Model {finetuned_model_name} failed during validation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        results_summary.append({\n",
    "            \"model_name\": finetuned_model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"split\": \"test\",\n",
    "            \"iou\": IOU_THRESHOLDS,\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": str(e)\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "if results_summary:\n",
    "    results_df = pd.DataFrame(results_summary)\n",
    "    print('\\nüìä Final Validation Results:')\n",
    "    display(results_df)\n",
    "else:\n",
    "    print('\\n‚ö†Ô∏è  No validation results - model training not completed yet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35471d99",
   "metadata": {},
   "source": [
    "## 10. Generate Training Report (PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b66f810c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING COMPREHENSIVE TRAINING PDF REPORT\n",
      "================================================================================\n",
      "\n",
      "‚úì Comprehensive Training PDF generated: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251130_075906/yolo11s_training_report.pdf\n"
     ]
    }
   ],
   "source": [
    "# GENERATE COMPREHENSIVE TRAINING PDF REPORT\n",
    "# ============================================================================\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors as rl_colors\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "import platform\n",
    "import psutil\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('GENERATING COMPREHENSIVE TRAINING PDF REPORT')\n",
    "print('=' * 80)\n",
    "\n",
    "pdf_training_report_path = TRAIN_DIR / f'{MODEL_NAME}_training_report.pdf'\n",
    "doc = SimpleDocTemplate(str(pdf_training_report_path), pagesize=A4,\n",
    "                       rightMargin=30, leftMargin=30,\n",
    "                       topMargin=30, bottomMargin=30)\n",
    "story = []\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "# Custom styles\n",
    "title_style = ParagraphStyle('Title', parent=styles['Heading1'], fontSize=24,\n",
    "                             textColor=rl_colors.HexColor('#2c3e50'), alignment=TA_CENTER, spaceAfter=20)\n",
    "heading_style = ParagraphStyle('Heading', parent=styles['Heading2'], fontSize=16,\n",
    "                               textColor=rl_colors.HexColor('#34495e'), spaceAfter=12, spaceBefore=20)\n",
    "normal_style = ParagraphStyle('Normal', parent=styles['Normal'], fontSize=10)\n",
    "\n",
    "# --- Title ---\n",
    "story.append(Paragraph(f'{MODEL_NAME} Final Training Report', title_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- System Info ---\n",
    "story.append(Paragraph('System Information', heading_style))\n",
    "sys_info_data = [\n",
    "    ['OS', platform.system() + ' ' + platform.release()],\n",
    "    ['Python Version', platform.python_version()],\n",
    "    ['PyTorch Version', torch.__version__],\n",
    "    ['CUDA Available', str(torch.cuda.is_available())],\n",
    "    ['Device', device],\n",
    "    ['RAM (GB)', f\"{psutil.virtual_memory().total/1e9:.2f}\"],\n",
    "]\n",
    "sys_table = Table(sys_info_data, colWidths=[2.5*inch, 3.5*inch])\n",
    "sys_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#95a5a6')),\n",
    "    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "    ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "]))\n",
    "story.append(sys_table)\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Dataset Info ---\n",
    "story.append(Paragraph('Dataset Information', heading_style))\n",
    "# Wrap class names text for better readability\n",
    "class_names_text = ', '.join(str(name) for name in CLASS_NAMES.values())\n",
    "class_names_wrapped = Paragraph(class_names_text, normal_style)\n",
    "\n",
    "dataset_info_data = [\n",
    "    ['Property', 'Value'],\n",
    "    ['Dataset', YOLO_DATASET_ROOT.name],\n",
    "    ['Number of Classes', str(NUM_CLASSES)],\n",
    "    ['Train Images', str(dataset_stats.get('train', {}).get('images', 'N/A'))],\n",
    "    ['Val Images', str(dataset_stats.get('val', {}).get('images', 'N/A'))],\n",
    "    ['Test Images', str(dataset_stats.get('test', {}).get('images', 'N/A'))],\n",
    "    ['Data YAML', str(DATA_YAML_PATH.name)],\n",
    "]\n",
    "dataset_table = Table(dataset_info_data, colWidths=[2*inch, 4*inch])\n",
    "dataset_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#16a085')),\n",
    "    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "]))\n",
    "story.append(dataset_table)\n",
    "story.append(Spacer(1, 6))\n",
    "# Add class names separately with wrapping\n",
    "story.append(Paragraph('<b>Classes:</b>', normal_style))\n",
    "story.append(class_names_wrapped)\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Optimization Summary ---\n",
    "story.append(Paragraph('Optimization Summary', heading_style))\n",
    "opt_summary_data = [\n",
    "    ['Metric', 'Value'],\n",
    "    ['Tuning Run', TUNING_RUN_NAME],\n",
    "    ['Total Trials', str(tuning_metadata.get('total_trials', 'N/A')) if not USE_DEFAULT_CONFIG and  tuning_metadata_path.exists() else 'N/A'],\n",
    "    ['Completed Trials', str(tuning_metadata.get('completed_trials', 'N/A')) if not USE_DEFAULT_CONFIG and  tuning_metadata_path.exists() else 'N/A'],\n",
    "    ['Best Trial Number', str(tuning_metadata.get('best_trial', 'N/A')) if not USE_DEFAULT_CONFIG and  tuning_metadata_path.exists() else 'N/A'],\n",
    "    ['Best Trial mAP@0.5', f\"{tuning_metadata.get('best_map50', 0):.4f}\" if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists() else 'N/A'],\n",
    "    ['Final Training Epochs', str(EPOCHS_FINAL_TRAINING)],\n",
    "]\n",
    "opt_table = Table(opt_summary_data, colWidths=[3*inch, 3*inch])\n",
    "opt_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#f39c12')),\n",
    "    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "]))\n",
    "story.append(opt_table)\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Optimized Hyperparameters ---\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Optimized Hyperparameters Used', heading_style))\n",
    "hyperparam_data = [['Parameter', 'Value']]\n",
    "for key, value in best_params.items():\n",
    "    hyperparam_data.append([key, f\"{value:.6f}\" if isinstance(value, float) else str(value)])\n",
    "hyperparam_table = Table(hyperparam_data, colWidths=[3*inch, 3*inch])\n",
    "hyperparam_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#3498db')),\n",
    "    ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "    ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "]))\n",
    "story.append(hyperparam_table)\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Training Process Details ---\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Training Process Analysis', heading_style))\n",
    "\n",
    "# Try to load training results CSV for detailed epoch-by-epoch analysis\n",
    "# YOLO saves results.csv directly in the training run directory\n",
    "results_csv = TRAIN_DIR / 'results.csv'\n",
    "if results_csv.exists():\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib\n",
    "        matplotlib.use('Agg')\n",
    "        \n",
    "        # Load results\n",
    "        training_results = pd.read_csv(results_csv)\n",
    "        training_results.columns = training_results.columns.str.strip()\n",
    "        \n",
    "        story.append(Paragraph('Epoch-by-Epoch Training Metrics', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        # Create comprehensive training curves\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(12, 14))\n",
    "        fig.suptitle('Training Progress Over Epochs', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Loss Curves (Train/Box/Cls/DFL)\n",
    "        ax = axes[0, 0]\n",
    "        if 'train/box_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['train/box_loss'], \n",
    "                   label='Box Loss', color='#e74c3c', linewidth=2)\n",
    "        if 'train/cls_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['train/cls_loss'], \n",
    "                   label='Class Loss', color='#3498db', linewidth=2)\n",
    "        if 'train/dfl_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['train/dfl_loss'], \n",
    "                   label='DFL Loss', color='#f39c12', linewidth=2)\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Loss', fontsize=10)\n",
    "        ax.set_title('Training Loss Components', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Validation Loss Curves\n",
    "        ax = axes[0, 1]\n",
    "        if 'val/box_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['val/box_loss'], \n",
    "                   label='Box Loss', color='#e74c3c', linewidth=2, linestyle='--')\n",
    "        if 'val/cls_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['val/cls_loss'], \n",
    "                   label='Class Loss', color='#3498db', linewidth=2, linestyle='--')\n",
    "        if 'val/dfl_loss' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['val/dfl_loss'], \n",
    "                   label='DFL Loss', color='#f39c12', linewidth=2, linestyle='--')\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Loss', fontsize=10)\n",
    "        ax.set_title('Validation Loss Components', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. mAP Metrics Over Epochs\n",
    "        ax = axes[1, 0]\n",
    "        if 'metrics/mAP50(B)' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['metrics/mAP50(B)'], \n",
    "                   label='mAP@0.5', color='#27ae60', linewidth=2.5, marker='o', markersize=4)\n",
    "        if 'metrics/mAP50-95(B)' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['metrics/mAP50-95(B)'], \n",
    "                   label='mAP@0.5:0.95', color='#16a085', linewidth=2.5, marker='s', markersize=4)\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('mAP', fontsize=10)\n",
    "        ax.set_title('mAP Progression', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # 4. Precision and Recall\n",
    "        ax = axes[1, 1]\n",
    "        if 'metrics/precision(B)' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['metrics/precision(B)'], \n",
    "                   label='Precision', color='#9b59b6', linewidth=2.5, marker='^', markersize=4)\n",
    "        if 'metrics/recall(B)' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['metrics/recall(B)'], \n",
    "                   label='Recall', color='#e67e22', linewidth=2.5, marker='v', markersize=4)\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Score', fontsize=10)\n",
    "        ax.set_title('Precision & Recall Progression', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # 5. Learning Rate Schedule\n",
    "        ax = axes[2, 0]\n",
    "        if 'lr/pg0' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['lr/pg0'], \n",
    "                   label='LR Group 0', color='#34495e', linewidth=2)\n",
    "        if 'lr/pg1' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['lr/pg1'], \n",
    "                   label='LR Group 1', color='#7f8c8d', linewidth=2)\n",
    "        if 'lr/pg2' in training_results.columns:\n",
    "            ax.plot(training_results['epoch'], training_results['lr/pg2'], \n",
    "                   label='LR Group 2', color='#95a5a6', linewidth=2)\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Learning Rate', fontsize=10)\n",
    "        ax.set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Combined Loss (Train vs Val)\n",
    "        ax = axes[2, 1]\n",
    "        # Calculate total train loss if components available\n",
    "        train_loss_cols = [col for col in training_results.columns if 'train/' in col and 'loss' in col]\n",
    "        val_loss_cols = [col for col in training_results.columns if 'val/' in col and 'loss' in col]\n",
    "        \n",
    "        if train_loss_cols:\n",
    "            train_total = training_results[train_loss_cols].sum(axis=1)\n",
    "            ax.plot(training_results['epoch'], train_total, \n",
    "                   label='Total Train Loss', color='#c0392b', linewidth=2.5)\n",
    "        if val_loss_cols:\n",
    "            val_total = training_results[val_loss_cols].sum(axis=1)\n",
    "            ax.plot(training_results['epoch'], val_total, \n",
    "                   label='Total Val Loss', color='#2980b9', linewidth=2.5, linestyle='--')\n",
    "        ax.set_xlabel('Epoch', fontsize=10)\n",
    "        ax.set_ylabel('Total Loss', fontsize=10)\n",
    "        ax.set_title('Total Loss: Train vs Validation', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save training curves\n",
    "        training_curves_img = TRAIN_DIR / 'report_training_curves.png'\n",
    "        plt.savefig(training_curves_img, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Add to PDF\n",
    "        story.append(Image(str(training_curves_img), width=6.5*inch, height=7.5*inch))\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "        # Epoch-by-Epoch Summary Table (First 10, Middle 5, Last 10)\n",
    "        story.append(PageBreak())\n",
    "        story.append(Paragraph('Detailed Epoch Metrics', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        # Select representative epochs\n",
    "        total_epochs = len(training_results)\n",
    "        if total_epochs <= 25:\n",
    "            selected_epochs = training_results\n",
    "        else:\n",
    "            # First 10, middle 5, last 10\n",
    "            first_10 = training_results.head(10)\n",
    "            middle_start = total_epochs // 2 - 2\n",
    "            middle_5 = training_results.iloc[middle_start:middle_start+5]\n",
    "            last_10 = training_results.tail(10)\n",
    "            selected_epochs = pd.concat([first_10, middle_5, last_10])\n",
    "        \n",
    "        # Build table with key metrics\n",
    "        epoch_table_data = [['Epoch', 'Train Loss', 'Val Loss', 'mAP@0.5', 'mAP@0.5:0.95', 'Precision', 'Recall']]\n",
    "        \n",
    "        for _, row in selected_epochs.iterrows():\n",
    "            epoch_num = int(row['epoch']) if 'epoch' in row else '?'\n",
    "            \n",
    "            # Calculate total losses\n",
    "            train_loss = sum([row.get(col, 0) for col in train_loss_cols]) if train_loss_cols else 'N/A'\n",
    "            val_loss = sum([row.get(col, 0) for col in val_loss_cols]) if val_loss_cols else 'N/A'\n",
    "            \n",
    "            map50 = f\"{row.get('metrics/mAP50(B)', 0):.4f}\" if 'metrics/mAP50(B)' in row else 'N/A'\n",
    "            map50_95 = f\"{row.get('metrics/mAP50-95(B)', 0):.4f}\" if 'metrics/mAP50-95(B)' in row else 'N/A'\n",
    "            precision = f\"{row.get('metrics/precision(B)', 0):.4f}\" if 'metrics/precision(B)' in row else 'N/A'\n",
    "            recall = f\"{row.get('metrics/recall(B)', 0):.4f}\" if 'metrics/recall(B)' in row else 'N/A'\n",
    "            \n",
    "            epoch_table_data.append([\n",
    "                str(epoch_num),\n",
    "                f\"{train_loss:.4f}\" if isinstance(train_loss, (int, float)) else train_loss,\n",
    "                f\"{val_loss:.4f}\" if isinstance(val_loss, (int, float)) else val_loss,\n",
    "                map50,\n",
    "                map50_95,\n",
    "                precision,\n",
    "                recall\n",
    "            ])\n",
    "        \n",
    "        epoch_table = Table(epoch_table_data, colWidths=[0.6*inch, 1*inch, 1*inch, 0.9*inch, 1.1*inch, 0.9*inch, 0.9*inch])\n",
    "        epoch_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#8e44ad')),\n",
    "            ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "            ('FONTSIZE', (0,0), (-1,-1), 8),\n",
    "            ('GRID', (0,0), (-1,-1), 0.5, rl_colors.black),\n",
    "            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "            ('ALIGN', (0,0), (-1,-1), 'CENTER'),\n",
    "        ]))\n",
    "        story.append(epoch_table)\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "        # Training Summary Statistics\n",
    "        story.append(Paragraph('Training Statistics Summary', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        stats_data = [['Metric', 'Initial', 'Final', 'Best', 'Change']]\n",
    "        \n",
    "        # mAP@0.5\n",
    "        if 'metrics/mAP50(B)' in training_results.columns:\n",
    "            map50_col = training_results['metrics/mAP50(B)']\n",
    "            stats_data.append([\n",
    "                'mAP@0.5',\n",
    "                f\"{map50_col.iloc[0]:.4f}\",\n",
    "                f\"{map50_col.iloc[-1]:.4f}\",\n",
    "                f\"{map50_col.max():.4f}\",\n",
    "                f\"+{map50_col.iloc[-1] - map50_col.iloc[0]:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        # mAP@0.5:0.95\n",
    "        if 'metrics/mAP50-95(B)' in training_results.columns:\n",
    "            map50_95_col = training_results['metrics/mAP50-95(B)']\n",
    "            stats_data.append([\n",
    "                'mAP@0.5:0.95',\n",
    "                f\"{map50_95_col.iloc[0]:.4f}\",\n",
    "                f\"{map50_95_col.iloc[-1]:.4f}\",\n",
    "                f\"{map50_95_col.max():.4f}\",\n",
    "                f\"+{map50_95_col.iloc[-1] - map50_95_col.iloc[0]:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        # Precision\n",
    "        if 'metrics/precision(B)' in training_results.columns:\n",
    "            prec_col = training_results['metrics/precision(B)']\n",
    "            stats_data.append([\n",
    "                'Precision',\n",
    "                f\"{prec_col.iloc[0]:.4f}\",\n",
    "                f\"{prec_col.iloc[-1]:.4f}\",\n",
    "                f\"{prec_col.max():.4f}\",\n",
    "                f\"+{prec_col.iloc[-1] - prec_col.iloc[0]:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        # Recall\n",
    "        if 'metrics/recall(B)' in training_results.columns:\n",
    "            recall_col = training_results['metrics/recall(B)']\n",
    "            stats_data.append([\n",
    "                'Recall',\n",
    "                f\"{recall_col.iloc[0]:.4f}\",\n",
    "                f\"{recall_col.iloc[-1]:.4f}\",\n",
    "                f\"{recall_col.max():.4f}\",\n",
    "                f\"+{recall_col.iloc[-1] - recall_col.iloc[0]:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        stats_table = Table(stats_data, colWidths=[1.5*inch, 1*inch, 1*inch, 1*inch, 1*inch])\n",
    "        stats_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#2ecc71')),\n",
    "            ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "            ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "            ('ALIGN', (1,1), (-1,-1), 'CENTER'),\n",
    "        ]))\n",
    "        story.append(stats_table)\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "    except Exception as e:\n",
    "        story.append(Paragraph(f'Could not load detailed training results: {str(e)}', normal_style))\n",
    "        story.append(Spacer(1, 12))\n",
    "else:\n",
    "    story.append(Paragraph('Training results file (results.csv) not found. Train the model to generate detailed metrics.', normal_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Final Model Performance ---\n",
    "if 'final_metrics' in globals():\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Final Model Performance', heading_style))\n",
    "    \n",
    "    perf_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['mAP@0.5', f\"{final_metrics['map50']:.4f}\"],\n",
    "        ['mAP@0.5:0.95', f\"{final_metrics['map50_95']:.4f}\"],\n",
    "        ['Precision', f\"{final_metrics['precision']:.4f}\"],\n",
    "        ['Recall', f\"{final_metrics['recall']:.4f}\"],\n",
    "    ]\n",
    "    perf_table = Table(perf_data, colWidths=[3*inch, 3*inch])\n",
    "    perf_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#27ae60')),\n",
    "        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "    ]))\n",
    "    story.append(perf_table)\n",
    "    story.append(Spacer(1, 12))\n",
    "\n",
    "# --- Test Set Validation Results ---\n",
    "if 'result' in globals() and 'metrics' in result:\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Test Set Validation Results', heading_style))\n",
    "    story.append(Spacer(1, 6))\n",
    "    \n",
    "    # Test metrics summary\n",
    "    test_metrics = result['metrics']\n",
    "    test_overall = test_metrics['overall']\n",
    "    test_yolo = test_metrics['yolo_metrics']\n",
    "    test_model_info = result['model_info']\n",
    "    \n",
    "    # Model Architecture and Performance Summary\n",
    "    story.append(Paragraph('Model Architecture & Performance', styles['Heading3']))\n",
    "    model_arch_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Model Name', finetuned_model_name],\n",
    "        ['Parameters (M)', f\"{test_model_info.get('params', 0) / 1e6:.2f}\"],\n",
    "        ['Model Size (MB)', f\"{test_model_info.get('size(MB)', 0):.2f}\"],\n",
    "        ['FLOPs (G)', f\"{test_model_info.get('FLOPs(G)', 0):.2f}\"],\n",
    "        ['Layers', str(test_model_info.get('layers', 'N/A'))],\n",
    "        ['Inference Speed (FPS)', f\"{test_metrics['fps']:.2f}\"],\n",
    "        ['IoU Threshold', f\"{IOU_THRESHOLDS:.2f}\"],\n",
    "    ]\n",
    "    model_arch_table = Table(model_arch_data, colWidths=[2.5*inch, 3.5*inch])\n",
    "    model_arch_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#34495e')),\n",
    "        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "        ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "        ('ALIGN', (1,1), (-1,-1), 'CENTER'),\n",
    "    ]))\n",
    "    story.append(model_arch_table)\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Overall Performance Metrics\n",
    "    story.append(Paragraph('Overall Performance Metrics on Test Set', styles['Heading3']))\n",
    "    test_perf_data = [\n",
    "        ['Metric', 'Confusion Matrix', 'YOLO Validation'],\n",
    "        ['Precision', f\"{test_overall['precision']:.4f}\", f\"{test_yolo['precision']:.4f}\"],\n",
    "        ['Recall', f\"{test_overall['recall']:.4f}\", f\"{test_yolo['recall']:.4f}\"],\n",
    "        ['F1-Score', f\"{test_overall['f1']:.4f}\", 'N/A'],\n",
    "        ['mAP@0.5 (Overall)', 'N/A', f\"{test_yolo['map50']:.4f}\"],\n",
    "        ['mAP@0.5:0.95 (Overall)', 'N/A', f\"{test_yolo['map50_95']:.4f}\"],\n",
    "    ]\n",
    "    test_perf_table = Table(test_perf_data, colWidths=[2*inch, 2*inch, 2*inch])\n",
    "    test_perf_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#e74c3c')),\n",
    "        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "        ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "        ('ALIGN', (1,0), (-1,-1), 'CENTER'),\n",
    "    ]))\n",
    "    story.append(test_perf_table)\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Per-Class mAP@0.5 and Performance\n",
    "    if 'df_metrics' in result and not result['df_metrics'].empty:\n",
    "        story.append(PageBreak())\n",
    "        story.append(Paragraph('Per-Class Performance Metrics', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        df_metrics = result['df_metrics']\n",
    "        \n",
    "        # Per-class table with all metrics\n",
    "        per_class_data = [['Class', 'Precision', 'Recall', 'F1-Score', 'mAP@0.5', 'TP', 'FP', 'FN']]\n",
    "        for _, row in df_metrics.iterrows():\n",
    "            per_class_data.append([\n",
    "                str(row['Class']),\n",
    "                f\"{row['Precision']:.4f}\",\n",
    "                f\"{row['Recall']:.4f}\",\n",
    "                f\"{row['F1-Score']:.4f}\",\n",
    "                f\"{row['mAP@0.5']:.4f}\",\n",
    "                str(int(row['TP'])),\n",
    "                str(int(row['FP'])),\n",
    "                str(int(row['FN']))\n",
    "            ])\n",
    "        \n",
    "        per_class_table = Table(per_class_data, colWidths=[1.2*inch, 0.8*inch, 0.7*inch, 0.8*inch, 0.8*inch, 0.5*inch, 0.5*inch, 0.5*inch])\n",
    "        per_class_table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#9b59b6')),\n",
    "            ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "            ('FONTSIZE', (0,0), (-1,-1), 8),\n",
    "            ('GRID', (0,0), (-1,-1), 0.5, rl_colors.black),\n",
    "            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "            ('ALIGN', (1,0), (-1,-1), 'CENTER'),\n",
    "        ]))\n",
    "        story.append(per_class_table)\n",
    "        story.append(Spacer(1, 12))\n",
    "        \n",
    "        # mAP@0.5 by Class visualization\n",
    "        map50_by_class_img = result['figures'].get('map50_by_class')\n",
    "        if map50_by_class_img and Path(map50_by_class_img).exists():\n",
    "            try:\n",
    "                story.append(Paragraph('mAP@0.5 Distribution by Class', styles['Heading4']))\n",
    "                story.append(Spacer(1, 4))\n",
    "                story.append(Image(str(map50_by_class_img), width=6.5*inch, height=4.5*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except Exception as img_error:\n",
    "                story.append(Paragraph(f'Could not load mAP by class chart: {str(img_error)}', normal_style))\n",
    "    \n",
    "    # IoU Information\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Intersection over Union (IoU) Analysis', styles['Heading3']))\n",
    "    story.append(Spacer(1, 6))\n",
    "    \n",
    "    iou_info_text = f\"\"\"\n",
    "    <b>IoU Threshold Used:</b> {IOU_THRESHOLDS:.2f}<br/>\n",
    "    <br/>\n",
    "    IoU (Intersection over Union) measures the overlap between predicted and ground truth bounding boxes.\n",
    "    A prediction is considered correct (True Positive) when IoU ‚â• {IOU_THRESHOLDS:.2f}.<br/>\n",
    "    <br/>\n",
    "    <b>Per-Class IoU Performance:</b><br/>\n",
    "    The confusion matrix and per-class metrics above show detection accuracy at IoU={IOU_THRESHOLDS:.2f} threshold.\n",
    "    Each class's True Positives (TP) represent detections with IoU ‚â• {IOU_THRESHOLDS:.2f}.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(iou_info_text, normal_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Confusion Matrix (Test Set)', styles['Heading3']))\n",
    "    story.append(Spacer(1, 6))\n",
    "    \n",
    "    confusion_matrix_img = result['figures'].get('confusion_matrix')\n",
    "    if confusion_matrix_img and Path(confusion_matrix_img).exists():\n",
    "        try:\n",
    "            with PILImage.open(confusion_matrix_img) as img:\n",
    "                img_width, img_height = img.size\n",
    "                aspect_ratio = img_height / img_width\n",
    "                pdf_width = 6*inch\n",
    "                pdf_height = pdf_width * aspect_ratio\n",
    "                if pdf_height > 6*inch:\n",
    "                    pdf_height = 6*inch\n",
    "                    pdf_width = pdf_height / aspect_ratio\n",
    "                story.append(Image(str(confusion_matrix_img), width=pdf_width, height=pdf_height))\n",
    "                story.append(Spacer(1, 12))\n",
    "        except Exception as img_error:\n",
    "            story.append(Paragraph(f'Could not load confusion matrix: {str(img_error)}', normal_style))\n",
    "    else:\n",
    "        story.append(Paragraph('Confusion matrix image not available.', normal_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Test Performance Curves - Only add section if curves exist\n",
    "    pr_curve_img = result['figures'].get('pr_curve')\n",
    "    f1_curve_img = result['figures'].get('f1_curve')\n",
    "    overall_metrics_img = result['figures'].get('overall_metrics')\n",
    "    \n",
    "    has_curves = (\n",
    "        (pr_curve_img and Path(pr_curve_img).exists()) or\n",
    "        (f1_curve_img and Path(f1_curve_img).exists()) or\n",
    "        (overall_metrics_img and Path(overall_metrics_img).exists())\n",
    "    )\n",
    "    \n",
    "    if has_curves:\n",
    "        story.append(PageBreak())\n",
    "        story.append(Paragraph('Test Set Performance Curves', styles['Heading3']))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        # PR Curve\n",
    "        if pr_curve_img and Path(pr_curve_img).exists():\n",
    "            try:\n",
    "                story.append(Paragraph('Precision-Recall Curve', styles['Heading4']))\n",
    "                story.append(Image(str(pr_curve_img), width=6*inch, height=4*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except Exception as img_error:\n",
    "                story.append(Paragraph(f'Could not load PR curve: {str(img_error)}', normal_style))\n",
    "        \n",
    "        # F1 Curve\n",
    "        if f1_curve_img and Path(f1_curve_img).exists():\n",
    "            try:\n",
    "                story.append(Paragraph('F1-Score Curve', styles['Heading4']))\n",
    "                story.append(Image(str(f1_curve_img), width=6*inch, height=4*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except Exception as img_error:\n",
    "                story.append(Paragraph(f'Could not load F1 curve: {str(img_error)}', normal_style))\n",
    "        \n",
    "        # Overall Metrics\n",
    "        if overall_metrics_img and Path(overall_metrics_img).exists():\n",
    "            try:\n",
    "                story.append(Paragraph('Overall Metrics Visualization', styles['Heading4']))\n",
    "                story.append(Image(str(overall_metrics_img), width=6.5*inch, height=5*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except Exception as img_error:\n",
    "                story.append(Paragraph(f'Could not load overall metrics: {str(img_error)}', normal_style))\n",
    "    \n",
    "    # Sample Comparison Images\n",
    "    if 'comparison_data' in result and result['comparison_data']:\n",
    "        story.append(PageBreak())\n",
    "        story.append(Paragraph('Sample Predictions: Ground Truth vs Model Output', heading_style))\n",
    "        story.append(Spacer(1, 6))\n",
    "        \n",
    "        # Add up to 6 comparison images\n",
    "        for idx, comp in enumerate(result['comparison_data'][:6], 1):\n",
    "            comp_img_path = comp.get('comparison_image_path')\n",
    "            if comp_img_path and Path(comp_img_path).exists():\n",
    "                try:\n",
    "                    # Add attributes info\n",
    "                    attributes = comp.get('attributes', {})\n",
    "                    attr_text = f\"Sample {idx} - Weather: {attributes.get('weather', 'unknown')}, Scene: {attributes.get('scene', 'unknown')}, Time: {attributes.get('timeofday', 'unknown')}\"\n",
    "                    story.append(Paragraph(attr_text, normal_style))\n",
    "                    story.append(Spacer(1, 4))\n",
    "                    \n",
    "                    # Add comparison image\n",
    "                    with PILImage.open(comp_img_path) as img:\n",
    "                        img_width, img_height = img.size\n",
    "                        aspect_ratio = img_height / img_width\n",
    "                        pdf_width = 6.5*inch\n",
    "                        pdf_height = pdf_width * aspect_ratio\n",
    "                        if pdf_height > 4*inch:\n",
    "                            pdf_height = 4*inch\n",
    "                            pdf_width = pdf_height / aspect_ratio\n",
    "                        story.append(Image(str(comp_img_path), width=pdf_width, height=pdf_height))\n",
    "                    \n",
    "                    # Add object count info\n",
    "                    gt_count = comp.get('gt_count', 0)\n",
    "                    pred_count = comp.get('pred_count', 0)\n",
    "                    count_text = f\"Ground Truth: {gt_count} objects | Predictions: {pred_count} objects\"\n",
    "                    story.append(Paragraph(count_text, ParagraphStyle('Small', parent=normal_style, fontSize=8, textColor=rl_colors.grey)))\n",
    "                    story.append(Spacer(1, 15))\n",
    "                    \n",
    "                    # Page break after every 2 comparisons\n",
    "                    if idx % 2 == 0 and idx < len(result['comparison_data'][:6]):\n",
    "                        story.append(PageBreak())\n",
    "                        \n",
    "                except Exception as img_error:\n",
    "                    story.append(Paragraph(f'Could not load comparison {idx}: {str(img_error)}', normal_style))\n",
    "                    story.append(Spacer(1, 12))\n",
    "\n",
    "elif 'results_summary' in globals() and len(results_summary) > 0 and results_summary[0].get('status') == 'ok':\n",
    "    # Fallback: Show basic info from results_summary\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Test Set Validation Results', heading_style))\n",
    "    \n",
    "    res = results_summary[0]\n",
    "    fallback_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Model', res.get('model_name', 'N/A')],\n",
    "        ['Precision (YOLO)', f\"{res.get('precision_yolo', 0):.4f}\"],\n",
    "        ['Recall (YOLO)', f\"{res.get('recall_yolo', 0):.4f}\"],\n",
    "        ['mAP@0.5', f\"{res.get('map50', 0):.4f}\"],\n",
    "        ['mAP@0.5:0.95', f\"{res.get('map50_95', 0):.4f}\"],\n",
    "        ['Parameters (M)', f\"{res.get('params_m', 0):.2f}\"],\n",
    "        ['Size (MB)', f\"{res.get('size_mb', 0):.2f}\"],\n",
    "        ['FPS', f\"{res.get('fps', 0):.2f}\"],\n",
    "    ]\n",
    "    fallback_table = Table(fallback_data, colWidths=[3*inch, 3*inch])\n",
    "    fallback_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), rl_colors.HexColor('#95a5a6')),\n",
    "        ('TEXTCOLOR', (0,0), (-1,0), rl_colors.whitesmoke),\n",
    "        ('GRID', (0,0), (-1,-1), 1, rl_colors.black),\n",
    "    ]))\n",
    "    story.append(fallback_table)\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Try to load images from run_dir if available\n",
    "    if 'run_dir' in res:\n",
    "        run_dir = Path(res['run_dir'])\n",
    "        \n",
    "        # Try confusion matrix\n",
    "        confusion_img = run_dir / 'confusion_matrix.png'\n",
    "        if confusion_img.exists():\n",
    "            try:\n",
    "                story.append(PageBreak())\n",
    "                story.append(Paragraph('Confusion Matrix', styles['Heading3']))\n",
    "                story.append(Image(str(confusion_img), width=6*inch, height=5*inch))\n",
    "                story.append(Spacer(1, 12))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Try comparison images\n",
    "        comparisons_dir = run_dir / 'sample_comparisons'\n",
    "        if comparisons_dir.exists():\n",
    "            comparison_imgs = sorted(comparisons_dir.glob('comparison_*.png'))[:4]\n",
    "            if comparison_imgs:\n",
    "                story.append(PageBreak())\n",
    "                story.append(Paragraph('Sample Predictions', styles['Heading3']))\n",
    "                for comp_img in comparison_imgs:\n",
    "                    try:\n",
    "                        story.append(Image(str(comp_img), width=6.5*inch, height=3.5*inch))\n",
    "                        story.append(Spacer(1, 10))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "# --- Footer ---\n",
    "story.append(Spacer(1, 20))\n",
    "story.append(Paragraph('Generated by YOLO Training Notebook', ParagraphStyle('Footer', parent=styles['Normal'], alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "story.append(Paragraph('BDD100K Dataset - Computer Vision Project', ParagraphStyle('Footer2', parent=styles['Normal'], alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "\n",
    "# Build PDF\n",
    "try:\n",
    "    doc.build(story)\n",
    "    print(f'\\n‚úì Comprehensive Training PDF generated: {pdf_training_report_path}')\n",
    "except Exception as e:\n",
    "    print(f'\\n‚ùå Error generating PDF: {e}')\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09278e",
   "metadata": {},
   "source": [
    "## 11. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e9576f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINAL TRAINING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "üìä Project: yolo11s on bdd100k_yolo_limited\n",
      "üìÖ Date: 2025-12-01 01:11:41\n",
      "\n",
      "üî¨ Tuning Run Used:\n",
      "  Run Name: None\n",
      "  Run Path: None\n",
      "\n",
      "üéØ Training Run:\n",
      "  Run Name: yolo11s_train_20251130_075906\n",
      "  Run Path: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251130_075906\n",
      "  Epochs: 90\n",
      "  Batch Size: 32\n",
      "\n",
      "üéØ Final Model Performance:\n",
      "  mAP@0.5: 0.5199\n",
      "  mAP@0.5:0.95: 0.2954\n",
      "  Precision: 0.6090\n",
      "  Recall: 0.4738\n",
      "\n",
      "üìÅ Generated Files:\n",
      "\n",
      "  üéØ Training Results (in yolo11s_train_20251130_075906):\n",
      "    - training_log.json\n",
      "    - weights/best.pt\n",
      "    - weights/last.pt\n",
      "    - results.csv\n",
      "  üìÑ Training PDF Report:\n",
      "    - yolo11s_training_report.pdf\n",
      "\n",
      "  üéØ Final Model Package:\n",
      "    - yolo11s_finetuned_20251201.pt\n",
      "    - yolo11s_finetuned_20251201_metadata.json\n",
      "    Location: /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201\n",
      "\n",
      "üìÇ All results saved to:\n",
      "  Tuning: None\n",
      "  Training: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251130_075906\n",
      "  Final Model: /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201\n",
      "\n",
      "üöÄ Next Steps:\n",
      "  1. Review training PDF report: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251130_075906/yolo11s_training_report.pdf\n",
      "  2. Review training plots and metrics in: /home/adminai/src-code/CV/project_repo/tune_train/training/yolo11s_train_20251130_075906\n",
      "  3. Use final model for inference: /home/adminai/src-code/CV/project_repo/models/yolo11s_finetuned_20251201/yolo11s_finetuned_20251201.pt\n",
      "  4. Evaluate on test set using yolo_test scripts\n",
      "  5. Consider fine-tuning with different datasets or model sizes\n",
      "\n",
      "üìù To Resume Training:\n",
      "  Set RESUME_TRAINING_RUN_NAME = \"yolo11s_train_20251130_075906\"\n",
      "  Then re-run this notebook\n",
      "\n",
      "================================================================================\n",
      "SUCCESS! ‚úì\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n\\n')\n",
    "print('=' * 80)\n",
    "print('FINAL TRAINING COMPLETE!')\n",
    "print('=' * 80)\n",
    "\n",
    "print(f'\\nüìä Project: {MODEL_NAME} on {YOLO_DATASET_ROOT.name}')\n",
    "print(f'üìÖ Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "# Tuning Summary\n",
    "print(f'\\nüî¨ Tuning Run Used:')\n",
    "print(f'  Run Name: {TUNING_RUN_NAME}')\n",
    "print(f'  Run Path: {TUNE_DIR}')\n",
    "\n",
    "if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "    print(f'  Total Trials: {tuning_metadata.get(\"total_trials\", \"N/A\")}')\n",
    "    print(f'  Completed Trials: {tuning_metadata.get(\"completed_trials\", \"N/A\")}')\n",
    "    print(f'  Best Trial: {tuning_metadata.get(\"best_trial\", \"N/A\")}')\n",
    "    print(f'  Best Trial mAP@0.5: {tuning_metadata.get(\"best_map50\", 0):.4f}')\n",
    "    if 'optimization_duration' in tuning_metadata:\n",
    "        print(f'  Tuning Duration: {tuning_metadata[\"optimization_duration\"]}')\n",
    "\n",
    "# Training Summary\n",
    "print(f'\\nüéØ Training Run:')\n",
    "print(f'  Run Name: {RUN_NAME_TRAINING}')\n",
    "print(f'  Run Path: {TRAIN_DIR}')\n",
    "print(f'  Epochs: {EPOCHS_FINAL_TRAINING}')\n",
    "print(f'  Batch Size: {BATCH_SIZE}')\n",
    "\n",
    "if 'final_metrics' in globals():\n",
    "    print(f'\\nüéØ Final Model Performance:')\n",
    "    print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n",
    "    print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n",
    "    print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n",
    "    print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n",
    "    \n",
    "    # Show improvement if available\n",
    "    if not USE_DEFAULT_CONFIG and tuning_metadata_path.exists():\n",
    "        tuning_best_map = tuning_metadata.get('best_map50', 0)\n",
    "        if tuning_best_map > 0:\n",
    "            improvement = final_metrics['map50'] - tuning_best_map\n",
    "            print(f'\\nüìà Improvement vs Tuning:')\n",
    "            print(f'  Tuning Best: {tuning_best_map:.4f}')\n",
    "            print(f'  Training Final: {final_metrics[\"map50\"]:.4f}')\n",
    "            print(f'  Improvement: {improvement:+.4f} ({improvement/tuning_best_map*100:+.2f}%)')\n",
    "\n",
    "print(f'\\nüìÅ Generated Files:')\n",
    "if not USE_DEFAULT_CONFIG:\n",
    "    print(f'\\n  üìä Tuning Results (in {TUNE_DIR.name}):')\n",
    "    print(f'    - best_hyperparameters.json')\n",
    "    print(f'    - best_hparams.yaml')\n",
    "    print(f'    - checkpoint_log.json')\n",
    "    print(f'    - optuna_study.pkl')\n",
    "\n",
    "print(f'\\n  üéØ Training Results (in {TRAIN_DIR.name}):')\n",
    "print(f'    - training_log.json')\n",
    "print(f'    - weights/best.pt')\n",
    "print(f'    - weights/last.pt')\n",
    "print(f'    - results.csv')\n",
    "print(f'  üìÑ Training PDF Report:')\n",
    "print(f'    - {MODEL_NAME}_training_report.pdf')\n",
    "\n",
    "if 'final_model_path' in globals():\n",
    "    print(f'\\n  üéØ Final Model Package:')\n",
    "    print(f'    - {final_model_path.name}')\n",
    "    print(f'    - {metadata_path.name}')\n",
    "    print(f'    Location: {model_save_dir}')\n",
    "\n",
    "print(f'\\nüìÇ All results saved to:')\n",
    "print(f'  Tuning: {TUNE_DIR}')\n",
    "print(f'  Training: {TRAIN_DIR}')\n",
    "if 'model_save_dir' in globals():\n",
    "    print(f'  Final Model: {model_save_dir}')\n",
    "\n",
    "print(f'\\nüöÄ Next Steps:')\n",
    "print(f'  1. Review training PDF report: {TRAIN_DIR / f\"{MODEL_NAME}_training_report.pdf\"}')\n",
    "print(f'  2. Review training plots and metrics in: {TRAIN_DIR}')\n",
    "if 'final_model_path' in globals():\n",
    "    print(f'  3. Use final model for inference: {final_model_path}')\n",
    "    print(f'  4. Evaluate on test set using yolo_test scripts')\n",
    "else:\n",
    "    print(f'  3. Complete training to generate final model')\n",
    "print(f'  5. Consider fine-tuning with different datasets or model sizes')\n",
    "\n",
    "print('\\nüìù To Resume Training:')\n",
    "print(f'  Set RESUME_TRAINING_RUN_NAME = \"{RUN_NAME_TRAINING}\"')\n",
    "print(f'  Then re-run this notebook')\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('SUCCESS! ‚úì')\n",
    "print('=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YOLO Env)",
   "language": "python",
   "name": "yolo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
